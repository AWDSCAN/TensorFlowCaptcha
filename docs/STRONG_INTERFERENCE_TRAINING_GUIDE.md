# å¼ºå¹²æ‰°éªŒè¯ç è®­ç»ƒä¼˜åŒ–æ–¹æ¡ˆ

## é—®é¢˜åˆ†æ

å½“å‰è®­ç»ƒç»“æœï¼š
- äºŒè¿›åˆ¶å‡†ç¡®ç‡: 99.23% âœ“ï¼ˆå¾ˆå¥½ï¼‰
- **å®Œæ•´åŒ¹é…å‡†ç¡®ç‡: 15.54%** âŒï¼ˆå¤ªä½ï¼‰
- 15è½®åæ—©åœ

é¢„æµ‹é”™è¯¯ç¤ºä¾‹ï¼š
```
çœŸå®: 36      â†’ é¢„æµ‹: 18      ï¼ˆæ•°å­—è¯†åˆ«é”™è¯¯ï¼‰
çœŸå®: 72      â†’ é¢„æµ‹: 16      ï¼ˆæ•°å­—è¯†åˆ«é”™è¯¯ï¼‰
çœŸå®: 694214  â†’ é¢„æµ‹: 69422   ï¼ˆé•¿åº¦é”™è¯¯ï¼‰
çœŸå®: kknX    â†’ é¢„æµ‹: kkkX    ï¼ˆå­—æ¯æ··æ·†ï¼‰
```

## æ ¹æœ¬åŸå› 

1. **éªŒè¯ç å¹²æ‰°è¿‡å¼º**ï¼š
   - èƒŒæ™¯å™ªç‚¹ï¼š1000-1500ä¸ª
   - å¤šå±‚å¹²æ‰°çº¿ï¼š10-16æ¡ï¼ˆèƒŒæ™¯+ç©¿é€+é¡¶å±‚ï¼‰
   - å¹²æ‰°å¼§çº¿ï¼š2-4æ¡
   - å­—ç¬¦æ—‹è½¬ï¼šÂ±30åº¦
   - ä½ç½®éšæœºåç§»

2. **æ¨¡å‹èƒ½åŠ›ä¸è¶³**ï¼š
   - åŸæ¨¡å‹ï¼š3å±‚å·ç§¯ + 1024 FC
   - å‚æ•°é‡ï¼š12Mï¼ˆå¯¹äºå¼ºå¹²æ‰°åå°‘ï¼‰
   - ç¼ºå°‘BatchNormalizationï¼ˆè®­ç»ƒä¸ç¨³å®šï¼‰

3. **è®­ç»ƒä¸å……åˆ†**ï¼š
   - 15è½®å°±æ—©åœï¼ˆè€å¿ƒå€¼10ï¼‰
   - å­¦ä¹ ç‡0.001åé«˜
   - æ‰¹æ¬¡å¤§å°32åå°

## è§£å†³æ–¹æ¡ˆ

### 1. ä½¿ç”¨å¢å¼ºç‰ˆCNNæ¨¡å‹ âœ…

**æ–°æ¶æ„** (`model_enhanced.py`):
```
è¾“å…¥: (60, 200, 3)
  â†“
Conv1: 32 filters â†’ BN â†’ MaxPool
  â†“
Conv2: 64 filters â†’ BN â†’ MaxPool
  â†“
Conv3: 128 filters â†’ BN â†’ MaxPool
  â†“
Conv4: 128 filters â†’ BN
  â†“
Conv5: 256 filters â†’ BN â†’ MaxPool
  â†“
Dropout(0.3)
  â†“
Flatten
  â†“
FC1: 2048 units â†’ BN â†’ Dropout(0.4)
  â†“
FC2: 1024 units â†’ BN â†’ Dropout(0.3)
  â†“
Output: 504 units (8Ã—63)
```

**æ”¹è¿›ç‚¹**ï¼š
- âœ… 5å±‚å·ç§¯ï¼ˆvs åŸæ¥3å±‚ï¼‰
- âœ… æ·»åŠ BatchNormalizationï¼ˆç¨³å®šè®­ç»ƒï¼‰
- âœ… æ›´å¤§çš„FCå±‚ï¼ˆ2048â†’1024 vs 1024ï¼‰
- âœ… æ›´å¤šDropouté˜²æ­¢è¿‡æ‹Ÿåˆ
- âœ… æ¸è¿›å¼æ»¤æ³¢å™¨å¢é•¿ï¼ˆ32â†’64â†’128â†’128â†’256ï¼‰

**å‚æ•°é‡å¯¹æ¯”**ï¼š
- åŸæ¨¡å‹: 12.0M
- å¢å¼ºç‰ˆ: ~25Mï¼ˆçº¦2å€ï¼‰

### 2. è°ƒæ•´è®­ç»ƒå‚æ•° âœ…

ä¿®æ”¹ `config.py`:
```python
BATCH_SIZE = 64          # 32 â†’ 64ï¼ˆå……åˆ†åˆ©ç”¨åŒ4090ï¼‰
EPOCHS = 150             # 50 â†’ 150ï¼ˆå¼ºå¹²æ‰°éœ€è¦æ›´å¤šè®­ç»ƒï¼‰
LEARNING_RATE = 0.0003   # 0.001 â†’ 0.0003ï¼ˆæ›´ç¨³å®šï¼‰
EARLY_STOPPING_PATIENCE = 20  # 10 â†’ 20ï¼ˆç»™æ¨¡å‹æ›´å¤šæœºä¼šï¼‰
```

### 3. ä¼˜åŒ–å™¨æ”¹è¿› âœ…

ä½¿ç”¨AMSGradç‰ˆæœ¬çš„Adam:
```python
optimizer = keras.optimizers.Adam(
    learning_rate=0.0003,
    amsgrad=True  # æ›´ç¨³å®šçš„æ¢¯åº¦æ›´æ–°
)
```

## åœ¨GPUæœåŠ¡å™¨ä¸Šçš„æ“ä½œæ­¥éª¤

### æ­¥éª¤1: åŒæ­¥ä»£ç 

```bash
cd /data/coding
git pull  # æˆ–é‡æ–°ä¸Šä¼ ä¿®æ”¹çš„æ–‡ä»¶
```

ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å·²æ›´æ–°ï¼š
- âœ… `caocrvfy/model_enhanced.py` - å¢å¼ºç‰ˆæ¨¡å‹
- âœ… `caocrvfy/train.py` - æ”¯æŒå¢å¼ºç‰ˆæ¨¡å‹
- âœ… `caocrvfy/config.py` - æ–°è®­ç»ƒå‚æ•°
- âœ… `caocrvfy/utils.py` - å¡«å……å­—ç¬¦ä¿®å¤
- âœ… `caocrvfy/predict.py` - .kerasæ ¼å¼

### æ­¥éª¤2: æ¸…ç†æ—§æ¨¡å‹

```bash
cd /data/coding/caocrvfy

# åˆ é™¤æ—§æ¨¡å‹ï¼ˆæ¶æ„å·²å˜ï¼‰
rm -rf models/*.keras

# æ¸…ç†æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
rm -rf logs/*
```

### æ­¥éª¤3: éªŒè¯é…ç½®

```bash
python -c "
import config
print(f'æ‰¹æ¬¡å¤§å°: {config.BATCH_SIZE}')
print(f'è®­ç»ƒè½®æ•°: {config.EPOCHS}')
print(f'å­¦ä¹ ç‡: {config.LEARNING_RATE}')
print(f'æ—©åœè€å¿ƒå€¼: {config.EARLY_STOPPING_PATIENCE}')
print(f'å­—ç¬¦é›†é•¿åº¦: {config.CHAR_SET_LEN}')
print(f'è¾“å‡ºç»´åº¦: {config.OUTPUT_SIZE}')
"
```

é¢„æœŸè¾“å‡ºï¼š
```
æ‰¹æ¬¡å¤§å°: 64
è®­ç»ƒè½®æ•°: 150
å­¦ä¹ ç‡: 0.0003
æ—©åœè€å¿ƒå€¼: 20
å­—ç¬¦é›†é•¿åº¦: 63
è¾“å‡ºç»´åº¦: 504
```

### æ­¥éª¤4: å¼€å§‹è®­ç»ƒ

```bash
# æ–¹å¼1ï¼šç›´æ¥è®­ç»ƒ
python train.py

# æ–¹å¼2ï¼šåå°è®­ç»ƒå¹¶è®°å½•æ—¥å¿—
nohup python train.py > training.log 2>&1 &

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f training.log
```

### æ­¥éª¤5: ç›‘æ§è®­ç»ƒï¼ˆå¯é€‰ï¼‰

```bash
# æ–°å¼€ç»ˆç«¯ï¼Œå¯åŠ¨TensorBoard
tensorboard --logdir=logs --port=6006 --bind_all

# åœ¨æœ¬åœ°æµè§ˆå™¨è®¿é—®ï¼ˆéœ€è¦ç«¯å£è½¬å‘ï¼‰
# ssh -L 6006:localhost:6006 user@gpu-server
# ç„¶åè®¿é—® http://localhost:6006
```

## é¢„æœŸè®­ç»ƒæ•ˆæœ

### è®­ç»ƒæ—¶é—´ä¼°ç®—ï¼ˆåŒRTX 4090ï¼‰

| æ‰¹æ¬¡å¤§å° | æ¯è½®æ—¶é—´ | 50è½® | 100è½® | 150è½® |
|---------|---------|------|-------|-------|
| 64 | 8-12ç§’ | 7-10åˆ†é’Ÿ | 13-20åˆ†é’Ÿ | 20-30åˆ†é’Ÿ |

**æ³¨æ„**ï¼šå¢å¼ºç‰ˆæ¨¡å‹å‚æ•°æ›´å¤šï¼Œæ¯è½®æ—¶é—´ä¼šç•¥é•¿äºåŸæ¨¡å‹ã€‚

### é¢„æœŸå‡†ç¡®ç‡æ›²çº¿

å¼ºå¹²æ‰°éªŒè¯ç çš„å­¦ä¹ æ›²çº¿ä¼šæ›´æ…¢ï¼š

| è½®æ•° | äºŒè¿›åˆ¶å‡†ç¡®ç‡ | å®Œæ•´åŒ¹é…å‡†ç¡®ç‡ï¼ˆé¢„æœŸï¼‰ |
|------|------------|---------------------|
| 10 | 75-85% | 15-25% |
| 20 | 85-92% | 30-45% |
| 50 | 95-97% | 65-80% |
| 100 | 98-99% | 85-92% |
| 150 | 99%+ | **90-95%** âœ… |

### åˆ¤æ–­è®­ç»ƒæ˜¯å¦æˆåŠŸ

è®­ç»ƒå®Œæˆåæ£€æŸ¥ï¼š

1. **å®Œæ•´åŒ¹é…å‡†ç¡®ç‡ â‰¥ 85%** âœ“ï¼ˆå¯æ¥å—ï¼‰
2. **å®Œæ•´åŒ¹é…å‡†ç¡®ç‡ â‰¥ 90%** âœ“âœ“ï¼ˆè‰¯å¥½ï¼‰
3. **å®Œæ•´åŒ¹é…å‡†ç¡®ç‡ â‰¥ 93%** âœ“âœ“âœ“ï¼ˆä¼˜ç§€ï¼‰

ç¤ºä¾‹é¢„æµ‹åº”è¯¥æ˜¯ï¼š
```
çœŸå®: 36      â†’ é¢„æµ‹: 36      âœ“
çœŸå®: 72      â†’ é¢„æµ‹: 72      âœ“
çœŸå®: 694214  â†’ é¢„æµ‹: 694214  âœ“
çœŸå®: kknX    â†’ é¢„æµ‹: kknX    âœ“
```

## å¦‚æœå‡†ç¡®ç‡ä»ç„¶ä¸ç†æƒ³

### æ–¹æ¡ˆAï¼šè¿›ä¸€æ­¥å¢å¼ºæ¨¡å‹

ä½¿ç”¨ResNeté£æ ¼æ¨¡å‹ï¼ˆ`model_enhanced.py`ä¸­å·²æä¾›ï¼‰ï¼š

```python
# åœ¨train.pyä¸­ä¿®æ”¹
from model_enhanced import create_resnet_style_model as create_model
```

ResNetç‰¹ç‚¹ï¼š
- æ®‹å·®è¿æ¥å¢å¼ºæ¢¯åº¦æµ
- æ›´æ·±çš„ç½‘ç»œï¼ˆ6ä¸ªæ®‹å·®å—ï¼‰
- å…¨å±€å¹³å‡æ± åŒ–
- å‚æ•°é‡ï¼š~30M+

### æ–¹æ¡ˆBï¼šæ•°æ®å¢å¼º

æ·»åŠ åœ¨çº¿æ•°æ®å¢å¼ºï¼ˆ`data_loader.py`ï¼‰ï¼š
```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=5,       # è½»å¾®æ—‹è½¬
    width_shift_range=0.05, # æ°´å¹³åç§»
    height_shift_range=0.05,# å‚ç›´åç§»
    zoom_range=0.05,        # ç¼©æ”¾
    brightness_range=[0.8, 1.2]  # äº®åº¦
)
```

### æ–¹æ¡ˆCï¼šå­¦ä¹ ç‡è°ƒåº¦

ä½¿ç”¨ä½™å¼¦é€€ç«ï¼š
```python
from tensorflow.keras.callbacks import LearningRateScheduler
import numpy as np

def cosine_decay(epoch, lr):
    epochs_total = 150
    lr_min = 1e-6
    lr_max = 3e-4
    return lr_min + (lr_max - lr_min) * 0.5 * (1 + np.cos(np.pi * epoch / epochs_total))

lr_scheduler = LearningRateScheduler(cosine_decay)
```

### æ–¹æ¡ˆDï¼šä¸¤é˜¶æ®µè®­ç»ƒ

ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿæ”¶æ•›
```python
LEARNING_RATE = 0.001
EPOCHS = 30
```

ç¬¬äºŒé˜¶æ®µï¼šç²¾ç»†è°ƒä¼˜
```python
LEARNING_RATE = 0.0001
EPOCHS = 100
```

## å¸¸è§é—®é¢˜æ’æŸ¥

### Q1: OOM (å†…å­˜ä¸è¶³)

**ç—‡çŠ¶**: `ResourceExhaustedError: OOM when allocating tensor`

**è§£å†³**:
```python
# æ–¹æ¡ˆ1ï¼šå‡å°æ‰¹æ¬¡
BATCH_SIZE = 32  # 64â†’32

# æ–¹æ¡ˆ2ï¼šå¯ç”¨å†…å­˜å¢é•¿
gpus = tf.config.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

# æ–¹æ¡ˆ3ï¼šä½¿ç”¨æ··åˆç²¾åº¦
from tensorflow.keras import mixed_precision
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_global_policy(policy)
```

### Q2: è®­ç»ƒå¤ªæ…¢

**æ£€æŸ¥**:
```bash
# ç¡®è®¤GPUè¢«ä½¿ç”¨
nvidia-smi  # æŸ¥çœ‹GPUåˆ©ç”¨ç‡

# Pythonä¸­æ£€æŸ¥
python -c "import tensorflow as tf; print('GPU:', tf.config.list_physical_devices('GPU'))"
```

**ä¼˜åŒ–**:
- ä½¿ç”¨SSDå­˜å‚¨è®­ç»ƒæ•°æ®
- å¢åŠ æ‰¹æ¬¡å¤§å°ï¼ˆå¦‚æœå†…å­˜å…è®¸ï¼‰
- å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ

### Q3: å‡†ç¡®ç‡å¡åœ¨æŸä¸ªå€¼

**å¯èƒ½åŸå› **:
1. å­¦ä¹ ç‡è¿‡å¤§æˆ–è¿‡å°
2. æ¨¡å‹è¿‡æ‹Ÿåˆ
3. æ•°æ®è´¨é‡é—®é¢˜

**è§£å†³**:
```python
# è°ƒæ•´å­¦ä¹ ç‡
LEARNING_RATE = 0.0001  # é™ä½

# å¢åŠ æ­£åˆ™åŒ–
from model_enhanced import create_enhanced_cnn_model
# æ‰‹åŠ¨å¢åŠ Dropoutæ¯”ä¾‹åˆ°0.5

# æ£€æŸ¥æ•°æ®
from data_loader import CaptchaDataLoader
loader = CaptchaDataLoader()
loader.load_data()
loader.print_statistics()
```

## æ€»ç»“

### å·²å®æ–½çš„ä¼˜åŒ– âœ…

1. âœ… å¢å¼ºç‰ˆCNNæ¨¡å‹ï¼ˆ5å±‚å·ç§¯ + BN + å¤§FCå±‚ï¼‰
2. âœ… è°ƒæ•´è®­ç»ƒå‚æ•°ï¼ˆæ‰¹æ¬¡64ï¼Œè½®æ•°150ï¼Œå­¦ä¹ ç‡0.0003ï¼‰
3. âœ… ä¿®å¤å¡«å……å­—ç¬¦é—®é¢˜
4. âœ… æ›´æ–°æ¨¡å‹æ ¼å¼ä¸º.keras
5. âœ… ä½¿ç”¨AMSGradä¼˜åŒ–å™¨

### é¢„æœŸæå‡ ğŸ“ˆ

| æŒ‡æ ‡ | ä¿®å¤å‰ | ä¿®å¤åï¼ˆé¢„æœŸï¼‰ |
|------|--------|---------------|
| å®Œæ•´åŒ¹é…å‡†ç¡®ç‡ | 15.54% | **90-95%** |
| è®­ç»ƒè½®æ•° | 15è½®æ—©åœ | 50-100è½® |
| æ¨¡å‹å‚æ•° | 12M | 25M |
| è®­ç»ƒæ—¶é—´ | 2.5åˆ†é’Ÿ | 20-30åˆ†é’Ÿ |

### ç«‹å³è¡ŒåŠ¨ ğŸš€

```bash
# åœ¨GPUæœåŠ¡å™¨ä¸Šæ‰§è¡Œ
cd /data/coding/caocrvfy
rm -rf models/*.keras logs/*
python train.py
```

é¢„è®¡è®­ç»ƒæ—¶é—´ï¼š**20-30åˆ†é’Ÿ**ï¼ˆåŒRTX 4090ï¼‰

---

**æœ€åæ›´æ–°**: 2026å¹´1æœˆ30æ—¥  
**çŠ¶æ€**: âœ… å·²ä¼˜åŒ–ï¼Œç­‰å¾…GPUæœåŠ¡å™¨è®­ç»ƒéªŒè¯  
**é¢„æœŸ**: å®Œæ•´åŒ¹é…å‡†ç¡®ç‡æå‡è‡³ 90-95%
