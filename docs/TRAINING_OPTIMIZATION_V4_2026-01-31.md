# è®­ç»ƒv4.0ä¼˜åŒ–æŠ¥å‘Šï¼ˆå‚è€ƒcaptcha_trainer/trains.pyç­–ç•¥ï¼‰

**æ—¥æœŸ**: 2026-01-31  
**ä¼˜åŒ–ç‰ˆæœ¬**: v4.0  
**å‚è€ƒæ¥æº**: test/captcha_trainer (TensorFlow 1.14)  
**å½“å‰é¡¹ç›®**: TensorFlow 2.16.1

---

## ä¸€ã€ä¼˜åŒ–æ¦‚è¿°

æœ¬æ¬¡ä¼˜åŒ–å®Œæ•´å‚è€ƒäº† `test/captcha_trainer/trains.py` çš„è®­ç»ƒç­–ç•¥ï¼Œå°†å…¶æ ¸å¿ƒæ€æƒ³é€‚é…åˆ°TensorFlow 2.16.1é¡¹ç›®ä¸­ã€‚

### æ ¸å¿ƒæ”¹è¿›ç‚¹

1. âœ… **Step-basedéªŒè¯**: æ¯500æ­¥éªŒè¯ä¸€æ¬¡ï¼ˆè€Œéæ¯epochï¼‰
2. âœ… **æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡**: æ¯10000æ­¥Ã—0.98ï¼ˆé˜¶æ¢¯å¼è¡°å‡ï¼‰
3. âœ… **å¤šæ¡ä»¶ç»ˆæ­¢**: å‡†ç¡®ç‡ AND æŸå¤± AND æ­¥æ•°åŒæ—¶æ»¡è¶³
4. âœ… **Step-basedä¿å­˜**: æ¯100æ­¥ä¿å­˜checkpoint
5. âœ… **æ­¥æ•°é™åˆ¶**: æœ€å¤š50000æ­¥ï¼Œé˜²æ­¢æ­»å¾ªç¯

---

## äºŒã€è¯¦ç»†å¯¹æ¯”ï¼šv3.0 â†’ v4.0

### 2.1 éªŒè¯ç­–ç•¥

**v3.0ï¼ˆåŸå§‹ï¼‰**:
```python
# æ¯ä¸ªepochç»“æŸåéªŒè¯
model.fit(
    train_data,
    validation_data=val_data,
    epochs=200
)
```

**v4.0ï¼ˆå‚è€ƒtrains.pyï¼‰**:
```python
# Step-basedéªŒè¯ï¼šæ¯500æ­¥éªŒè¯ä¸€æ¬¡
class StepBasedCallbacks(keras.callbacks.Callback):
    def on_batch_end(self, batch, logs=None):
        if self.current_step % 500 == 0:
            # é‡‡æ ·1000ä¸ªéªŒè¯æ ·æœ¬
            # è®¡ç®—éªŒè¯æŸå¤±å’Œå®Œæ•´åŒ¹é…å‡†ç¡®ç‡
            # æ‰“å°éªŒè¯ç»“æœ
```

**ä¼˜åŠ¿**:
- éªŒè¯é¢‘ç‡æ›´çµæ´»ï¼Œä¸ä¾èµ–epochå¤§å°
- å¯ä»¥æ›´æ—©å‘ç°è®­ç»ƒé—®é¢˜
- å¤§æ•°æ®é›†ä¸ŠéªŒè¯æ›´åŠæ—¶ï¼ˆä¸ç”¨ç­‰ä¸€æ•´ä¸ªepochï¼‰

---

### 2.2 å­¦ä¹ ç‡è°ƒæ•´

**v3.0ï¼ˆåŸå§‹ï¼‰**:
```python
# ReduceLROnPlateau: 8è½®æ— æ”¹è¿›é™ä½50%
reduce_lr = keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=8,
    min_lr=5e-7
)
```

**v4.0ï¼ˆå‚è€ƒtrains.pyï¼‰**:
```python
# æŒ‡æ•°è¡°å‡ï¼šæ¯10000æ­¥Ã—0.98
lr_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.001,
    decay_steps=10000,
    decay_rate=0.98,
    staircase=True
)
```

**è¡°å‡æ›²çº¿å¯¹æ¯”**:
```
æ­¥æ•°      v3.0ï¼ˆæŒ‰éœ€è¡°å‡ï¼‰        v4.0ï¼ˆæŒ‡æ•°è¡°å‡ï¼‰
0        0.001000              0.001000
10000    0.001000ï¼ˆç­‰å¾…ï¼‰       0.000980 (-2.00%)
20000    0.000500ï¼ˆçªé™50%ï¼‰    0.000960 (-3.96%)
30000    0.000500              0.000941 (-5.88%)
40000    0.000250ï¼ˆçªé™50%ï¼‰    0.000922 (-7.76%)
50000    0.000250              0.000904 (-9.61%)
```

**ä¼˜åŠ¿**:
- å­¦ä¹ ç‡å¹³æ»‘è¡°å‡ï¼Œè®­ç»ƒæ›´ç¨³å®š
- ä¸ä¾èµ–éªŒè¯æŸå¤±æ³¢åŠ¨
- å¯é¢„æµ‹çš„è¡°å‡æ›²çº¿
- å‚è€ƒtrains.pyçš„æˆç†Ÿç­–ç•¥

---

### 2.3 ç»ˆæ­¢æ¡ä»¶

**v3.0ï¼ˆåŸå§‹ï¼‰**:
```python
# å•ä¸€æ—©åœæ¡ä»¶ï¼š35è½®æ— æ”¹è¿›
early_stop = DelayedEarlyStopping(
    monitor='val_loss',
    patience=35
)
```

**v4.0ï¼ˆå‚è€ƒtrains.pyçš„achieve_condï¼‰**:
```python
# å¤šæ¡ä»¶ç»ˆæ­¢
achieve_accuracy = full_match_acc >= 0.80
achieve_loss = val_loss <= 0.05
achieve_steps = steps >= 10000
over_max_steps = steps > 50000

if (achieve_accuracy and achieve_loss and achieve_steps) or over_max_steps:
    self.model.stop_training = True
```

**ç»ˆæ­¢åœºæ™¯å¯¹æ¯”**:
| åœºæ™¯ | å‡†ç¡®ç‡ | æŸå¤± | æ­¥æ•° | v3.0 | v4.0 |
|------|--------|------|------|------|------|
| æ—©æœŸé˜¶æ®µ | 0.50 | 0.20 | 1000 | ç»§ç»­ | ç»§ç»­ |
| å‡†ç¡®ç‡è¾¾æ ‡ä½†æŸå¤±é«˜ | 0.85 | 0.10 | 12000 | **åœæ­¢**âŒ | ç»§ç»­âœ… |
| å…¨éƒ¨è¾¾æ ‡ | 0.85 | 0.04 | 12000 | åœæ­¢ | åœæ­¢ |
| è¶…è¿‡æœ€å¤§æ­¥æ•° | 0.70 | 0.08 | 51000 | ç»§ç»­ | **åœæ­¢**âœ… |

**ä¼˜åŠ¿**:
- é˜²æ­¢è¿‡æ—©åœæ­¢ï¼ˆå•ä¸€æŒ‡æ ‡è¾¾æ ‡ä½†å…¶ä»–æœªè¾¾æ ‡ï¼‰
- é˜²æ­¢è¿‡æ™šåœæ­¢ï¼ˆè®¾ç½®æœ€å¤§æ­¥æ•°é™åˆ¶ï¼‰
- æ›´ç¬¦åˆéªŒè¯ç è¯†åˆ«çš„å®é™…éœ€æ±‚ï¼ˆå‡†ç¡®ç‡+æŸå¤±åŒä¿éšœï¼‰

---

### 2.4 ä¿å­˜ç­–ç•¥

**v3.0ï¼ˆåŸå§‹ï¼‰**:
```python
# åªä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼ˆepoch-basedï¼‰
checkpoint = keras.callbacks.ModelCheckpoint(
    filepath='best_model.keras',
    monitor='val_loss',
    save_best_only=True
)
```

**v4.0ï¼ˆå‚è€ƒtrains.pyï¼‰**:
```python
# Step-basedä¿å­˜ï¼šæ¯100æ­¥ä¿å­˜checkpoint
if self.current_step % 100 == 0:
    checkpoint_path = f'checkpoint_step_{self.current_step}.keras'
    self.model.save(checkpoint_path)
```

**ä¿å­˜æ–‡ä»¶ç¤ºä¾‹**:
```
models/
â”œâ”€â”€ best_model.keras              # æœ€ä¼˜æ¨¡å‹ï¼ˆä¿ç•™ï¼‰
â”œâ”€â”€ checkpoint_step_100.keras     # ç¬¬100æ­¥
â”œâ”€â”€ checkpoint_step_200.keras     # ç¬¬200æ­¥
â”œâ”€â”€ checkpoint_step_300.keras     # ç¬¬300æ­¥
â””â”€â”€ ...
```

**ä¼˜åŠ¿**:
- è®­ç»ƒä¸­æ–­å¯æ¢å¤åˆ°ä»»æ„checkpoint
- å¯ä»¥å›æº¯æŸ¥çœ‹è®­ç»ƒå†å²
- é˜²æ­¢æ„å¤–å´©æºƒä¸¢å¤±æ‰€æœ‰è¿›åº¦

---

## ä¸‰ã€å®ç°ç»†èŠ‚

### 3.1 StepBasedCallbackså®ç°

```python
class StepBasedCallbacks(keras.callbacks.Callback):
    """
    Step-basedè®­ç»ƒç­–ç•¥ï¼ˆå‚è€ƒcaptcha_trainer/trains.pyï¼‰
    """
    def __init__(self, val_data, model_dir, save_step=100, 
                 validation_steps=500, end_acc=0.80, end_loss=0.05, 
                 max_steps=50000):
        super().__init__()
        self.val_images, self.val_labels = val_data
        self.model_dir = model_dir
        self.save_step = save_step
        self.validation_steps = validation_steps
        self.end_acc = end_acc
        self.end_loss = end_loss
        self.max_steps = max_steps
        self.current_step = 0
        self.best_val_acc = 0
        self.best_val_loss = float('inf')
    
    def on_batch_end(self, batch, logs=None):
        self.current_step += 1
        
        # æ¯save_stepæ­¥ä¿å­˜
        if self.current_step % self.save_step == 0:
            checkpoint_path = os.path.join(
                self.model_dir, 
                f'checkpoint_step_{self.current_step}.keras'
            )
            self.model.save(checkpoint_path)
        
        # æ¯validation_stepsæ­¥éªŒè¯
        if self.current_step % self.validation_steps == 0:
            # é‡‡æ ·éªŒè¯
            sample_size = min(1000, len(self.val_images))
            indices = np.random.choice(
                len(self.val_images), 
                sample_size, 
                replace=False
            )
            sample_images = self.val_images[indices]
            sample_labels = self.val_labels[indices]
            
            # è®¡ç®—æŒ‡æ ‡
            val_results = self.model.evaluate(
                sample_images, 
                sample_labels, 
                verbose=0
            )
            val_loss = val_results[0]
            
            # è®¡ç®—å®Œæ•´åŒ¹é…å‡†ç¡®ç‡
            predictions = self.model.predict(sample_images, verbose=0)
            pred_texts = [vector_to_text(pred) for pred in predictions]
            true_texts = [vector_to_text(label) for label in sample_labels]
            full_match_acc = calculate_accuracy(true_texts, pred_texts)
            
            # å¤šæ¡ä»¶ç»ˆæ­¢æ£€æŸ¥
            achieve_accuracy = full_match_acc >= self.end_acc
            achieve_loss = val_loss <= self.end_loss
            achieve_steps = self.current_step >= 10000
            over_max_steps = self.current_step > self.max_steps
            
            if (achieve_accuracy and achieve_loss and achieve_steps) or over_max_steps:
                print("\n  ğŸ¯ æ»¡è¶³ç»ˆæ­¢æ¡ä»¶ï¼Œæå‰ç»ˆæ­¢è®­ç»ƒï¼")
                self.model.stop_training = True
```

### 3.2 æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡å®ç°

```python
def train_model(model, train_data, val_data, use_exponential_decay=True):
    if use_exponential_decay:
        # è®¡ç®—æ¯ä¸ªepochçš„æ­¥æ•°
        train_images, train_labels = train_data
        steps_per_epoch = len(train_images) // batch_size
        
        # åˆ›å»ºæŒ‡æ•°è¡°å‡è°ƒåº¦
        lr_schedule = keras.optimizers.schedules.ExponentialDecay(
            initial_learning_rate=0.001,
            decay_steps=10000,
            decay_rate=0.98,
            staircase=True
        )
        
        # é‡æ–°ç¼–è¯‘æ¨¡å‹
        model = compile_model(
            model, 
            learning_rate=lr_schedule
        )
```

---

## å››ã€è®­ç»ƒå‚æ•°é…ç½®

### 4.1 å®Œæ•´å‚æ•°è¡¨

| å‚æ•° | v3.0 | v4.0ï¼ˆå‚è€ƒtrains.pyï¼‰ | è¯´æ˜ |
|------|------|----------------------|------|
| **å­¦ä¹ ç‡ç­–ç•¥** | ReduceLROnPlateau | ExponentialDecay | æŒ‡æ•°è¡°å‡æ›´ç¨³å®š |
| åˆå§‹å­¦ä¹ ç‡ | 0.001 | 0.001 | ä¿æŒä¸å˜ |
| è¡°å‡æ­¥æ•° | - | 10000æ­¥ | æ¯10000æ­¥è¡°å‡ |
| è¡°å‡ç‡ | 0.5ï¼ˆçªé™ï¼‰ | 0.98ï¼ˆå¹³æ»‘ï¼‰ | å¹³æ»‘è¡°å‡2% |
| **éªŒè¯ç­–ç•¥** | æ¯epoch | æ¯500æ­¥ | step-based |
| éªŒè¯æ ·æœ¬æ•° | å…¨éƒ¨ | 1000ï¼ˆé‡‡æ ·ï¼‰ | åŠ å¿«éªŒè¯ |
| **ä¿å­˜ç­–ç•¥** | æœ€ä¼˜æ¨¡å‹ | æ¯100æ­¥ | step-based |
| **ç»ˆæ­¢æ¡ä»¶** | EarlyStopping | å¤šæ¡ä»¶ | acc&loss&steps |
| ç›®æ ‡å‡†ç¡®ç‡ | - | 80% | å®Œæ•´åŒ¹é… |
| ç›®æ ‡æŸå¤± | - | 0.05 | BCE Loss |
| æœ€å°æ­¥æ•° | - | 10000 | å……åˆ†è®­ç»ƒ |
| æœ€å¤§æ­¥æ•° | - | 50000 | é˜²æ­¢æ­»å¾ªç¯ |
| **è®­ç»ƒè½®æ•°** | 200 | 500 | æ­¥æ•°é™åˆ¶ä¸ºä¸» |
| **æ‰¹æ¬¡å¤§å°** | 128 | 128 | ä¿æŒä¸å˜ |

### 4.2 æ¨èé…ç½®

**å¿«é€Ÿæµ‹è¯•**ï¼ˆéªŒè¯ä»£ç ï¼‰:
```python
StepBasedCallbacks(
    save_step=50,
    validation_steps=100,
    end_acc=0.70,
    end_loss=0.10,
    max_steps=5000
)
```

**æ­£å¼è®­ç»ƒ**ï¼ˆå®Œæ•´æ•°æ®é›†ï¼‰:
```python
StepBasedCallbacks(
    save_step=100,
    validation_steps=500,
    end_acc=0.80,
    end_loss=0.05,
    max_steps=50000
)
```

**é«˜ç²¾åº¦è®­ç»ƒ**ï¼ˆè¿½æ±‚æè‡´ï¼‰:
```python
StepBasedCallbacks(
    save_step=100,
    validation_steps=300,
    end_acc=0.90,
    end_loss=0.02,
    max_steps=100000
)
```

---

## äº”ã€é¢„æœŸæ•ˆæœ

### 5.1 è®­ç»ƒç¨³å®šæ€§

**v3.0é—®é¢˜**:
- å­¦ä¹ ç‡çªé™å¯èƒ½å¯¼è‡´è®­ç»ƒéœ‡è¡
- å•ä¸€æ—©åœæ¡ä»¶å®¹æ˜“è¿‡æ—©/è¿‡æ™šåœæ­¢
- epoch-basedéªŒè¯åœ¨å¤§æ•°æ®é›†ä¸Šå“åº”æ…¢

**v4.0æ”¹è¿›**:
- æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡å¹³æ»‘ç¨³å®š
- å¤šæ¡ä»¶ç»ˆæ­¢æ›´åˆç†
- step-basedéªŒè¯å“åº”åŠæ—¶

### 5.2 è®­ç»ƒæ•ˆç‡

**ç†è®ºåˆ†æ**:
```
æ•°æ®é›†å¤§å°: 20000å¼ 
æ‰¹æ¬¡å¤§å°: 128
æ¯epochæ­¥æ•°: 20000/128 â‰ˆ 156æ­¥

v3.0éªŒè¯é¢‘ç‡:
- æ¯epochéªŒè¯ = æ¯156æ­¥éªŒè¯

v4.0éªŒè¯é¢‘ç‡:
- æ¯500æ­¥éªŒè¯

å¯¹æ¯”:
- å‰3ä¸ªepoch: v3.0éªŒè¯3æ¬¡ï¼Œv4.0éªŒè¯0æ¬¡ï¼ˆè¿˜æœªåˆ°500æ­¥ï¼‰
- å‰10ä¸ªepochï¼ˆ1560æ­¥ï¼‰: v3.0éªŒè¯10æ¬¡ï¼Œv4.0éªŒè¯3æ¬¡
- å‰50ä¸ªepochï¼ˆ7800æ­¥ï¼‰: v3.0éªŒè¯50æ¬¡ï¼Œv4.0éªŒè¯15æ¬¡

ç»“è®º:
- v4.0éªŒè¯æ¬¡æ•°æ›´å°‘ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«
- ä½†å…³é”®æ—¶åˆ»ï¼ˆæ¯500æ­¥ï¼‰ä»ä¼šéªŒè¯ï¼Œä¸ä¼šé”™è¿‡é‡è¦ä¿¡æ¯
```

### 5.3 checkpointæ¢å¤

**åœºæ™¯**: è®­ç»ƒåˆ°20000æ­¥æ—¶æ„å¤–ä¸­æ–­

**v3.0**:
- åªèƒ½æ¢å¤åˆ°æœ€åä¿å­˜çš„best_modelï¼ˆå¯èƒ½æ˜¯15000æ­¥æ—¶çš„ï¼‰
- ä¸¢å¤±5000æ­¥çš„è®­ç»ƒè¿›åº¦

**v4.0**:
```
models/
â”œâ”€â”€ checkpoint_step_19900.keras  # å¯æ¢å¤åˆ°19900æ­¥
â”œâ”€â”€ checkpoint_step_20000.keras  # æˆ–20000æ­¥
```
- æœ€å¤šä¸¢å¤±100æ­¥è¿›åº¦
- å¯é€‰æ‹©ä»»æ„checkpointç»§ç»­è®­ç»ƒ

---

## å…­ã€éªŒè¯æµ‹è¯•ç»“æœ

è¿è¡Œ `test_train_v4_optimization.py` æµ‹è¯•ç»“æœ:

```
================================================================================
æµ‹è¯•æ€»ç»“
================================================================================
Step-basedå›è°ƒ                   âœ“ é€šè¿‡
æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡                        âœ“ é€šè¿‡
å¤šæ¡ä»¶ç»ˆæ­¢é€»è¾‘                        âœ“ é€šè¿‡
è®­ç»ƒç­–ç•¥å¯¹æ¯”                         âœ“ é€šè¿‡

ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è®­ç»ƒv4.0ä¼˜åŒ–å·²å°±ç»ª
================================================================================
```

### æµ‹è¯•è¦†ç›–

1. âœ… Step-basedå›è°ƒåˆ›å»ºæˆåŠŸ
2. âœ… æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡æ›²çº¿æ­£ç¡®
3. âœ… å¤šæ¡ä»¶ç»ˆæ­¢é€»è¾‘éªŒè¯é€šè¿‡
4. âœ… ç­–ç•¥å¯¹æ¯”æ–‡æ¡£ç”Ÿæˆ

---

## ä¸ƒã€ä½¿ç”¨æŒ‡å—

### 7.1 å¯åŠ¨è®­ç»ƒ

```bash
# ä½¿ç”¨v4.0ä¼˜åŒ–ç­–ç•¥è®­ç»ƒ
cd caocrvfy
python train.py
```

### 7.2 ç›‘æ§è®­ç»ƒ

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šçœ‹åˆ°ï¼š

```
ğŸ“Š Step 500 éªŒè¯ç»“æœ:
    éªŒè¯æŸå¤±: 0.1234 | äºŒè¿›åˆ¶å‡†ç¡®ç‡: 0.8567
    å®Œæ•´åŒ¹é…: 72.34% | å­¦ä¹ ç‡: 0.000980
    â¬† æœ€ä½³å®Œæ•´åŒ¹é…å‡†ç¡®ç‡: 72.34%

ğŸ’¾ Step 600: ä¿å­˜checkpoint (loss=0.1123)

ğŸ“Š Step 1000 éªŒè¯ç»“æœ:
    éªŒè¯æŸå¤±: 0.0987 | äºŒè¿›åˆ¶å‡†ç¡®ç‡: 0.8912
    å®Œæ•´åŒ¹é…: 78.56% | å­¦ä¹ ç‡: 0.000980
    â¬† æœ€ä½³å®Œæ•´åŒ¹é…å‡†ç¡®ç‡: 78.56%
    â¬‡ æœ€ä½³éªŒè¯æŸå¤±: 0.0987

...

ğŸ¯ æ»¡è¶³ç»ˆæ­¢æ¡ä»¶:
    å‡†ç¡®ç‡è¾¾æ ‡: True (>=80.00%)
    æŸå¤±è¾¾æ ‡: True (<=0.05)
    æ­¥æ•°è¾¾æ ‡: True (>=10000)
    æˆ–è¶…è¿‡æœ€å¤§æ­¥æ•°: False (>50000)

âœ… æå‰ç»ˆæ­¢è®­ç»ƒï¼
```

### 7.3 æ¢å¤è®­ç»ƒ

å¦‚æœéœ€è¦ä»checkpointæ¢å¤ï¼š

```python
# åŠ è½½æŒ‡å®šæ­¥æ•°çš„checkpoint
model = keras.models.load_model('models/checkpoint_step_15000.keras')

# ç»§ç»­è®­ç»ƒ
history = train_model(
    model,
    train_data=(train_images, train_labels),
    val_data=(val_images, val_labels),
    callbacks=callbacks,
    use_exponential_decay=True
)
```

---

## å…«ã€æ€»ç»“ä¸å±•æœ›

### 8.1 æ ¸å¿ƒæˆæœ

æœ¬æ¬¡ä¼˜åŒ–æˆåŠŸå°† `test/captcha_trainer/trains.py` çš„æ ¸å¿ƒè®­ç»ƒç­–ç•¥é€‚é…åˆ°TensorFlow 2.16.1é¡¹ç›®ï¼š

1. âœ… **Step-basedéªŒè¯**: çµæ´»ã€åŠæ—¶
2. âœ… **æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡**: ç¨³å®šã€å¯é¢„æµ‹
3. âœ… **å¤šæ¡ä»¶ç»ˆæ­¢**: åˆç†ã€å¯é 
4. âœ… **Step-basedä¿å­˜**: å¯æ¢å¤ã€é˜²ä¸¢å¤±

### 8.2 å…³é”®å·®å¼‚

| ç»´åº¦ | captcha_trainer (TF1.14) | å½“å‰é¡¹ç›® (TF2.16.1) |
|------|-------------------------|-------------------|
| ä¼šè¯æ¨¡å¼ | Session-based | Eager Execution |
| æ•°æ®æ ¼å¼ | TFRecords | NumPyæ•°ç»„ |
| è®­ç»ƒå¾ªç¯ | æ‰‹åŠ¨batchå¾ªç¯ | model.fit() |
| å›è°ƒå®ç° | Sessionæ“ä½œ | Keras Callback |
| å­¦ä¹ ç‡è°ƒåº¦ | tf.train.exponential_decay | keras.optimizers.schedules |

è™½ç„¶åº•å±‚å®ç°ä¸åŒï¼Œä½†**æ ¸å¿ƒæ€æƒ³å®Œå…¨ä¸€è‡´**ã€‚

### 8.3 ä¸‹ä¸€æ­¥

1. **å®é™…è®­ç»ƒéªŒè¯**: è¿è¡Œå®Œæ•´è®­ç»ƒï¼Œè§‚å¯Ÿæ•ˆæœ
2. **æ€§èƒ½å¯¹æ¯”**: v3.0 vs v4.0å‡†ç¡®ç‡å¯¹æ¯”
3. **å‚æ•°è°ƒä¼˜**: æ ¹æ®å®é™…æ•°æ®è°ƒæ•´éªŒè¯é¢‘ç‡ã€ç»ˆæ­¢æ¡ä»¶
4. **æ–‡æ¡£æ›´æ–°**: å°†æˆåŠŸç»éªŒå†™å…¥QUICKSTART

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**ä¼˜åŒ–æ—¥æœŸ**: 2026-01-31  
**å‚è€ƒæ¥æº**: test/captcha_trainer/trains.py (TensorFlow 1.14)  
**é€‚é…ç‰ˆæœ¬**: TensorFlow 2.16.1  
**æµ‹è¯•çŠ¶æ€**: âœ… å…¨éƒ¨é€šè¿‡
