#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Kerasæ¨¡å‹åŠ è½½å’Œæµ‹è¯•è„šæœ¬
ç”¨äºæœ¬åœ°éªŒè¯è®­ç»ƒæ•ˆæœ

åŠŸèƒ½ï¼š
1. åŠ è½½å·²è®­ç»ƒçš„Kerasæ¨¡å‹
2. åœ¨éªŒè¯é›†/æµ‹è¯•é›†ä¸Šè¯„ä¼°æ€§èƒ½
3. æ˜¾ç¤ºé¢„æµ‹ç¤ºä¾‹å’Œé”™è¯¯åˆ†æ
4. ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    # æµ‹è¯•final_model
    python test_model.py
    
    # æµ‹è¯•æŒ‡å®šæ¨¡å‹
    python test_model.py --model models/best_model.keras
    
    # æµ‹è¯•GPUæœåŠ¡å™¨æ¨¡å‹
    python test_model.py --model /data/coding/caocrvfy/core/models/final_model.keras
    
    # æ˜¾ç¤ºæ›´å¤šç¤ºä¾‹
    python test_model.py --samples 50
    
    # åªæ˜¾ç¤ºé”™è¯¯ç¤ºä¾‹
    python test_model.py --only-errors
"""

import os
import sys
import argparse
import numpy as np
from tensorflow import keras

from core import config
from core.data_loader import CaptchaDataLoader
from core import utils


def load_model(model_path):
    """åŠ è½½Kerasæ¨¡å‹"""
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    print(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {model_path}")
    model = keras.models.load_model(model_path)
    print("   âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"   è¾“å…¥å½¢çŠ¶: {model.input_shape}")
    print(f"   è¾“å‡ºå½¢çŠ¶: {model.output_shape}")
    print(f"   å‚æ•°é‡: {model.count_params():,}")
    
    # è®¡ç®—æ¨¡å‹å¤§å°
    model_size = os.path.getsize(model_path) / (1024 * 1024)
    print(f"   æ–‡ä»¶å¤§å°: {model_size:.2f} MB")
    
    return model


def evaluate_model(model, val_images, val_labels):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    print("\n" + "=" * 70)
    print("ğŸ“ˆ æ¨¡å‹è¯„ä¼°")
    print("=" * 70)
    
    # 1. è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡
    print(f"\nè®¡ç®—éªŒè¯é›†æŸå¤±å’ŒæŒ‡æ ‡...")
    results = model.evaluate(val_images, val_labels, verbose=0)
    
    # è·å–æŒ‡æ ‡åç§°
    metric_names = model.metrics_names
    
    print(f"\néªŒè¯é›†æ€§èƒ½:")
    for name, value in zip(metric_names, results):
        if 'loss' in name:
            print(f"   {name}: {value:.6f}")
        else:
            print(f"   {name}: {value:.4f}")
    
    # 2. è®¡ç®—å®Œæ•´åŒ¹é…å‡†ç¡®ç‡
    print(f"\nè®¡ç®—å®Œæ•´éªŒè¯ç åŒ¹é…å‡†ç¡®ç‡...")
    predictions = model.predict(val_images, verbose=0)
    
    pred_texts = [utils.vector_to_text(pred) for pred in predictions]
    true_texts = [utils.vector_to_text(label) for label in val_labels]
    
    full_match_accuracy = utils.calculate_accuracy(true_texts, pred_texts)
    
    print(f"\nâœ¨ å®Œæ•´åŒ¹é…å‡†ç¡®ç‡: {full_match_accuracy:.4f} ({full_match_accuracy*100:.2f}%)")
    
    return {
        'loss': results[0],
        'binary_accuracy': results[1] if len(results) > 1 else None,
        'full_match_accuracy': full_match_accuracy,
        'predictions': pred_texts,
        'ground_truth': true_texts
    }


def analyze_errors(predictions, ground_truth, max_show=20):
    """åˆ†æé¢„æµ‹é”™è¯¯"""
    print("\n" + "=" * 70)
    print("ğŸ” é”™è¯¯åˆ†æ")
    print("=" * 70)
    
    # ç»Ÿè®¡é”™è¯¯
    errors = []
    for i, (pred, true) in enumerate(zip(predictions, ground_truth)):
        if pred != true:
            errors.append((i, pred, true))
    
    error_rate = len(errors) / len(predictions) * 100
    
    print(f"\né”™è¯¯ç»Ÿè®¡:")
    print(f"   æ€»æ ·æœ¬æ•°: {len(predictions)}")
    print(f"   é”™è¯¯æ•°é‡: {len(errors)}")
    print(f"   é”™è¯¯ç‡: {error_rate:.2f}%")
    
    if not errors:
        print("\nğŸ‰ å®Œç¾ï¼æ‰€æœ‰é¢„æµ‹éƒ½æ­£ç¡®ï¼")
        return
    
    # é”™è¯¯ç±»å‹åˆ†æ
    error_types = {
        'å­—ç¬¦æ··æ·†': 0,
        'ç©ºæ ¼é—®é¢˜': 0,
        'å­—ç¬¦ä¸¢å¤±': 0,
        'å­—ç¬¦å¢åŠ ': 0,
        'å®Œå…¨é”™è¯¯': 0
    }
    
    for _, pred, true in errors:
        pred_clean = pred.replace(' ', '')
        true_clean = true.replace(' ', '')
        
        if ' ' in pred and ' ' not in true:
            error_types['ç©ºæ ¼é—®é¢˜'] += 1
        elif len(pred_clean) < len(true_clean):
            error_types['å­—ç¬¦ä¸¢å¤±'] += 1
        elif len(pred_clean) > len(true_clean):
            error_types['å­—ç¬¦å¢åŠ '] += 1
        elif abs(len(pred) - len(true)) <= 2:
            error_types['å­—ç¬¦æ··æ·†'] += 1
        else:
            error_types['å®Œå…¨é”™è¯¯'] += 1
    
    print(f"\né”™è¯¯ç±»å‹åˆ†å¸ƒ:")
    for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
        if count > 0:
            percentage = count / len(errors) * 100
            print(f"   {error_type}: {count} ({percentage:.1f}%)")
    
    # æ˜¾ç¤ºé”™è¯¯ç¤ºä¾‹
    print(f"\né”™è¯¯ç¤ºä¾‹ï¼ˆå‰{min(max_show, len(errors))}ä¸ªï¼‰:")
    print("-" * 70)
    print(f"{'ç´¢å¼•':<8}{'çœŸå®å€¼':<20}{'é¢„æµ‹å€¼':<20}{'é”™è¯¯ç±»å‹':<15}")
    print("-" * 70)
    
    for i, (idx, pred, true) in enumerate(errors[:max_show]):
        # åˆ¤æ–­é”™è¯¯ç±»å‹
        pred_clean = pred.replace(' ', '')
        true_clean = true.replace(' ', '')
        
        if ' ' in pred and ' ' not in true:
            error_type = 'ç©ºæ ¼é—®é¢˜'
        elif len(pred_clean) < len(true_clean):
            error_type = 'å­—ç¬¦ä¸¢å¤±'
        elif len(pred_clean) > len(true_clean):
            error_type = 'å­—ç¬¦å¢åŠ '
        elif abs(len(pred) - len(true)) <= 2:
            error_type = 'å­—ç¬¦æ··æ·†'
        else:
            error_type = 'å®Œå…¨é”™è¯¯'
        
        print(f"{idx:<8}{true:<20}{pred:<20}{error_type:<15}")
    
    if len(errors) > max_show:
        print(f"\n... è¿˜æœ‰ {len(errors) - max_show} ä¸ªé”™è¯¯æœªæ˜¾ç¤º")


def show_predictions(predictions, ground_truth, max_show=20, only_errors=False):
    """æ˜¾ç¤ºé¢„æµ‹ç¤ºä¾‹"""
    print("\n" + "=" * 70)
    print("ğŸ“ é¢„æµ‹ç¤ºä¾‹" + (" (ä»…é”™è¯¯)" if only_errors else ""))
    print("=" * 70)
    print(f"{'çœŸå®å€¼':<20}{'é¢„æµ‹å€¼':<20}{'åŒ¹é…':<10}")
    print("-" * 70)
    
    shown = 0
    for pred, true in zip(predictions, ground_truth):
        match = pred == true
        
        if only_errors and match:
            continue
        
        match_symbol = "âœ“" if match else "âœ—"
        print(f"{true:<20}{pred:<20}{match_symbol:<10}")
        
        shown += 1
        if shown >= max_show:
            break
    
    if shown < len(predictions):
        remaining = len(predictions) - shown
        print(f"\n... è¿˜æœ‰ {remaining} ä¸ªæ ·æœ¬æœªæ˜¾ç¤º")


def generate_report(model_path, results, output_file=None):
    """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
    print("\n" + "=" * 70)
    print("ğŸ“„ ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š")
    print("=" * 70)
    
    report_lines = []
    report_lines.append("=" * 70)
    report_lines.append("æ¨¡å‹è¯„ä¼°æŠ¥å‘Š")
    report_lines.append("=" * 70)
    report_lines.append(f"\næ¨¡å‹è·¯å¾„: {model_path}")
    report_lines.append(f"\néªŒè¯é›†å¤§å°: {len(results['ground_truth'])}")
    
    report_lines.append(f"\næ€§èƒ½æŒ‡æ ‡:")
    report_lines.append(f"  éªŒè¯é›†æŸå¤±: {results['loss']:.6f}")
    if results['binary_accuracy']:
        report_lines.append(f"  äºŒè¿›åˆ¶å‡†ç¡®ç‡: {results['binary_accuracy']:.4f}")
    report_lines.append(f"  å®Œæ•´åŒ¹é…å‡†ç¡®ç‡: {results['full_match_accuracy']:.4f} ({results['full_match_accuracy']*100:.2f}%)")
    
    # é”™è¯¯ç»Ÿè®¡
    errors = sum(1 for p, t in zip(results['predictions'], results['ground_truth']) if p != t)
    report_lines.append(f"\né”™è¯¯ç»Ÿè®¡:")
    report_lines.append(f"  æ­£ç¡®é¢„æµ‹: {len(results['ground_truth']) - errors}")
    report_lines.append(f"  é”™è¯¯é¢„æµ‹: {errors}")
    report_lines.append(f"  é”™è¯¯ç‡: {errors / len(results['ground_truth']) * 100:.2f}%")
    
    report_lines.append("\n" + "=" * 70)
    
    # æ‰“å°åˆ°æ§åˆ¶å°
    report_text = "\n".join(report_lines)
    print(report_text)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report_text)
        print(f"\nâœ“ æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
    
    return report_text


def main():
    parser = argparse.ArgumentParser(description='Kerasæ¨¡å‹æµ‹è¯•è„šæœ¬')
    parser.add_argument('--model', type=str, 
                        default='core/models/final_model.keras',
                        help='æ¨¡å‹è·¯å¾„ (é»˜è®¤: core/models/final_model.keras)')
    parser.add_argument('--samples', type=int, default=20,
                        help='æ˜¾ç¤ºçš„ç¤ºä¾‹æ•°é‡ (é»˜è®¤: 20)')
    parser.add_argument('--only-errors', action='store_true',
                        help='åªæ˜¾ç¤ºé”™è¯¯é¢„æµ‹')
    parser.add_argument('--report', type=str, default=None,
                        help='ä¿å­˜è¯„ä¼°æŠ¥å‘Šåˆ°æ–‡ä»¶')
    parser.add_argument('--analyze-errors', action='store_true',
                        help='è¯¦ç»†åˆ†æé”™è¯¯')
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("ğŸ§ª Kerasæ¨¡å‹æµ‹è¯•")
    print("=" * 70)
    
    try:
        # 1. åŠ è½½æ¨¡å‹
        print("\næ­¥éª¤ 1/4: åŠ è½½æ¨¡å‹")
        print("-" * 70)
        model = load_model(args.model)
        
        # 2. åŠ è½½éªŒè¯æ•°æ®
        print("\næ­¥éª¤ 2/4: åŠ è½½éªŒè¯æ•°æ®")
        print("-" * 70)
        loader = CaptchaDataLoader()
        loader.load_data()
        _, _, val_images, val_labels = loader.prepare_dataset()
        print(f"   éªŒè¯é›†å¤§å°: {len(val_images)}")
        
        # 3. è¯„ä¼°æ¨¡å‹
        print("\næ­¥éª¤ 3/4: è¯„ä¼°æ¨¡å‹")
        print("-" * 70)
        results = evaluate_model(model, val_images, val_labels)
        
        # 4. æ˜¾ç¤ºç»“æœ
        print("\næ­¥éª¤ 4/4: æ˜¾ç¤ºç»“æœ")
        print("-" * 70)
        
        # æ˜¾ç¤ºé¢„æµ‹ç¤ºä¾‹
        show_predictions(
            results['predictions'],
            results['ground_truth'],
            max_show=args.samples,
            only_errors=args.only_errors
        )
        
        # é”™è¯¯åˆ†æ
        if args.analyze_errors or args.only_errors:
            analyze_errors(
                results['predictions'],
                results['ground_truth'],
                max_show=args.samples
            )
        
        # ç”ŸæˆæŠ¥å‘Š
        if args.report or True:  # æ€»æ˜¯ç”Ÿæˆç®€è¦æŠ¥å‘Š
            output_file = args.report or 'evaluation_report.txt'
            generate_report(args.model, results, output_file if args.report else None)
        
        print("\n" + "=" * 70)
        print("âœ… æµ‹è¯•å®Œæˆï¼")
        print("=" * 70)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
