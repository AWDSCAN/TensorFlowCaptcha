#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¨¡å‹è®­ç»ƒæ¨¡å—
åŠŸèƒ½ï¼šè®­ç»ƒéªŒè¯ç è¯†åˆ«æ¨¡å‹
"""

import os
import sys
import time
import tensorflow as tf
from tensorflow import keras
import config
from data_loader import CaptchaDataLoader
import utils

# é€‰æ‹©ä½¿ç”¨å¢å¼ºç‰ˆæ¨¡å‹è¿˜æ˜¯åŸºç¡€æ¨¡å‹
USE_ENHANCED_MODEL = True  # æ”¹ä¸ºTrueä½¿ç”¨å¢å¼ºç‰ˆæ¨¡å‹

if USE_ENHANCED_MODEL:
    from model_enhanced import create_enhanced_cnn_model as create_model
    from model_enhanced import compile_model, print_model_summary
    print("ä½¿ç”¨å¢å¼ºç‰ˆCNNæ¨¡å‹ï¼ˆ5å±‚å·ç§¯ + BatchNorm + æ›´å¤§FCå±‚ï¼‰")
else:
    from model import create_cnn_model as create_model
    from model import compile_model, print_model_summary
    print("ä½¿ç”¨åŸºç¡€ç‰ˆCNNæ¨¡å‹ï¼ˆ3å±‚å·ç§¯ï¼‰")


def create_callbacks(model_dir=None, log_dir=None):
    """
    åˆ›å»ºè®­ç»ƒå›è°ƒå‡½æ•°
    
    å‚æ•°:
        model_dir: æ¨¡å‹ä¿å­˜ç›®å½•
        log_dir: æ—¥å¿—ä¿å­˜ç›®å½•
    
    è¿”å›:
        å›è°ƒå‡½æ•°åˆ—è¡¨
    """
    model_dir = model_dir or config.MODEL_DIR
    log_dir = log_dir or config.LOG_DIR
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(model_dir, exist_ok=True)
    os.makedirs(log_dir, exist_ok=True)
    
    callbacks = []
    
    # æ¨¡å‹æ£€æŸ¥ç‚¹ï¼šä¿å­˜æœ€ä¼˜æ¨¡å‹
    checkpoint_path = os.path.join(model_dir, 'best_model.keras')
    checkpoint = keras.callbacks.ModelCheckpoint(
        filepath=checkpoint_path,
        monitor='val_binary_accuracy',
        mode='max',
        save_best_only=True,
        save_weights_only=False,
        verbose=1
    )
    callbacks.append(checkpoint)
    
    # æ—©åœï¼šé˜²æ­¢è¿‡æ‹Ÿåˆï¼ˆå‚è€ƒæ–‡æ¡£ï¼š10è½®è€å¿ƒå€¼ï¼Œç›‘æ§å®Œæ•´åŒ¹é…å‡†ç¡®ç‡ï¼‰
    early_stop = keras.callbacks.EarlyStopping(
        monitor='val_binary_accuracy',
        mode='max',
        patience=10,  # å›ºå®š10è½®è€å¿ƒå€¼
        verbose=1,
        restore_best_weights=True,
        min_delta=0.001  # æœ€å°æ”¹è¿›é˜ˆå€¼
    )
    callbacks.append(early_stop)
    
    # TensorBoardï¼šå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
    tensorboard_log_dir = os.path.join(
        log_dir,
        f'run_{time.strftime("%Y%m%d_%H%M%S")}'
    )
    tensorboard = keras.callbacks.TensorBoard(
        log_dir=tensorboard_log_dir,
        histogram_freq=1,
        write_graph=True,
        write_images=False
    )
    callbacks.append(tensorboard)
    
    # å­¦ä¹ ç‡è¡°å‡ï¼ˆå‚è€ƒæ–‡æ¡£ï¼šæ›´æ¿€è¿›çš„è¡°å‡ç­–ç•¥ï¼‰
    reduce_lr = keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        mode='min',
        factor=0.5,  # è¡°å‡å› å­
        patience=3,  # 3è½®æ— æ”¹è¿›å³è¡°å‡ï¼ˆåŸ5â†’3ï¼Œæ›´å¿«å“åº”ï¼‰
        min_lr=1e-7,  # æœ€å°å­¦ä¹ ç‡
        verbose=1,
        cooldown=2  # è¡°å‡åå†·å´2è½®
    )
    callbacks.append(reduce_lr)
    
    # è®­ç»ƒè¿›åº¦æ‰“å° + ç›®æ ‡å‡†ç¡®ç‡è‡ªåŠ¨åœæ­¢ï¼ˆå‚è€ƒæ–‡æ¡£ï¼šè¾¾åˆ°95%è‡ªåŠ¨åœæ­¢ï¼‰
    class TrainingProgress(keras.callbacks.Callback):
        def __init__(self, target_accuracy=0.95):
            super().__init__()
            self.target_accuracy = target_accuracy
            self.best_accuracy = 0
        
        def on_epoch_end(self, epoch, logs=None):
            logs = logs or {}
            val_acc = logs.get('val_binary_accuracy', 0)
            
            # è·å–å½“å‰å­¦ä¹ ç‡ï¼ˆå…¼å®¹TensorFlow Variableå¯¹è±¡ï¼‰
            try:
                current_lr = float(keras.backend.get_value(self.model.optimizer.learning_rate))
            except:
                current_lr = float(self.model.optimizer.learning_rate.numpy())
            
            # æ‰“å°è®­ç»ƒè¿›åº¦
            print(f"\n[Epoch {epoch+1}] è®­ç»ƒå‡†ç¡®ç‡: {logs.get('binary_accuracy', 0):.4f} | "
                  f"éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f} | "
                  f"è®­ç»ƒæŸå¤±: {logs.get('loss', 0):.4f} | "
                  f"éªŒè¯æŸå¤±: {logs.get('val_loss', 0):.4f} | "
                  f"å­¦ä¹ ç‡: {current_lr:.6f}")
            
            # è·Ÿè¸ªæœ€ä½³å‡†ç¡®ç‡
            if val_acc > self.best_accuracy:
                self.best_accuracy = val_acc
                improvement = (val_acc - self.best_accuracy) * 100
                print(f"    â¬† éªŒè¯å‡†ç¡®ç‡æå‡è‡³: {val_acc*100:.2f}% (æœ€ä½³: {self.best_accuracy*100:.2f}%)")
            
            # è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡è‡ªåŠ¨åœæ­¢ï¼ˆå‚è€ƒæ–‡æ¡£æ€è·¯ï¼‰
            if val_acc >= self.target_accuracy:
                print(f"\nğŸ‰ è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡ {self.target_accuracy*100:.0f}%ï¼è®­ç»ƒè‡ªåŠ¨åœæ­¢ã€‚")
                self.model.stop_training = True
    
    callbacks.append(TrainingProgress(target_accuracy=0.95))  # 95%ç›®æ ‡
    
    return callbacks


def train_model(
    model,
    train_data,
    val_data,
    epochs=None,
    batch_size=None,
    callbacks=None
):
    """
    è®­ç»ƒæ¨¡å‹
    
    å‚æ•°:
        model: Kerasæ¨¡å‹
        train_data: è®­ç»ƒæ•°æ® (X, y)
        val_data: éªŒè¯æ•°æ® (X, y)
        epochs: è®­ç»ƒè½®æ•°
        batch_size: æ‰¹æ¬¡å¤§å°
        callbacks: å›è°ƒå‡½æ•°åˆ—è¡¨
    
    è¿”å›:
        è®­ç»ƒå†å²
    """
    epochs = epochs or config.EPOCHS
    batch_size = batch_size or config.BATCH_SIZE
    
    train_images, train_labels = train_data
    val_images, val_labels = val_data
    
    print("\n" + "=" * 80)
    print(" " * 30 + "å¼€å§‹è®­ç»ƒ")
    print("=" * 80)
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_images)}")
    print(f"éªŒè¯æ ·æœ¬æ•°: {len(val_images)}")
    print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"è®­ç»ƒè½®æ•°ä¸Šé™: {epochs} (æ—©åœè€å¿ƒå€¼: 10)")
    print(f"åˆå§‹å­¦ä¹ ç‡: {config.LEARNING_RATE}")
    print(f"ç›®æ ‡å‡†ç¡®ç‡: 95% (è¾¾åˆ°è‡ªåŠ¨åœæ­¢)")
    print(f"ä¼˜åŒ–å™¨: Adam with AMSGrad")
    print()
    
    # è®­ç»ƒæ¨¡å‹
    history = model.fit(
        train_images,
        train_labels,
        batch_size=batch_size,
        epochs=epochs,
        validation_data=(val_images, val_labels),
        callbacks=callbacks,
        verbose=2
    )
    
    return history


def evaluate_model(model, val_data):
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½
    
    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        val_data: éªŒè¯æ•°æ® (X, y)
    
    è¿”å›:
        è¯„ä¼°æŒ‡æ ‡å­—å…¸
    """
    val_images, val_labels = val_data
    
    print("\n" + "=" * 80)
    print(" " * 30 + "æ¨¡å‹è¯„ä¼°")
    print("=" * 80)
    
    # Kerasè¯„ä¼°
    results = model.evaluate(val_images, val_labels, verbose=0)
    
    print(f"éªŒè¯é›†æŸå¤±: {results[0]:.4f}")
    print(f"äºŒè¿›åˆ¶å‡†ç¡®ç‡: {results[1]:.4f}")
    print(f"ç²¾ç¡®ç‡: {results[2]:.4f}")
    print(f"å¬å›ç‡: {results[3]:.4f}")
    print()
    
    # å®Œæ•´åŒ¹é…å‡†ç¡®ç‡è¯„ä¼°
    print("è®¡ç®—å®Œæ•´éªŒè¯ç åŒ¹é…å‡†ç¡®ç‡...")
    predictions = model.predict(val_images, verbose=0)
    
    # è§£ç é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
    pred_texts = [utils.vector_to_text(pred) for pred in predictions]
    true_texts = [utils.vector_to_text(label) for label in val_labels]
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = utils.calculate_accuracy(true_texts, pred_texts)
    
    print(f"å®Œæ•´åŒ¹é…å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print()
    
    # æ˜¾ç¤ºç¤ºä¾‹é¢„æµ‹
    print("ç¤ºä¾‹é¢„æµ‹ï¼ˆå‰10ä¸ªï¼‰:")
    print("-" * 80)
    print(f"{'çœŸå®å€¼':<15} {'é¢„æµ‹å€¼':<15} {'åŒ¹é…':<10}")
    print("-" * 80)
    for i in range(min(10, len(true_texts))):
        match = "âœ“" if true_texts[i] == pred_texts[i] else "âœ—"
        print(f"{true_texts[i]:<15} {pred_texts[i]:<15} {match:<10}")
    print("=" * 80)
    
    return {
        'loss': results[0],
        'binary_accuracy': results[1],
        'precision': results[2],
        'recall': results[3],
        'full_match_accuracy': accuracy
    }


def save_model(model, save_path=None):
    """
    ä¿å­˜æ¨¡å‹
    
    å‚æ•°:
        model: Kerasæ¨¡å‹
        save_path: ä¿å­˜è·¯å¾„
    """
    save_path = save_path or os.path.join(config.MODEL_DIR, 'final_model.keras')
    
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    model.save(save_path)
    
    print(f"\nâœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
    
    # ä¿å­˜æ¨¡å‹å¤§å°
    model_size = os.path.getsize(save_path) / (1024 ** 2)
    print(f"æ¨¡å‹æ–‡ä»¶å¤§å°: {model_size:.2f} MB")


# ä¸»è®­ç»ƒæµç¨‹
def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    print("=" * 80)
    print(" " * 25 + "éªŒè¯ç è¯†åˆ«æ¨¡å‹è®­ç»ƒ")
    print("=" * 80)
    print()
    
    # 1. åŠ è½½æ•°æ®
    print("æ­¥éª¤ 1/5: åŠ è½½æ•°æ®")
    print("-" * 80)
    loader = CaptchaDataLoader()
    loader.load_data()
    loader.print_statistics()
    print()
    
    # 2. å‡†å¤‡æ•°æ®é›†
    print("æ­¥éª¤ 2/5: å‡†å¤‡æ•°æ®é›†")
    print("-" * 80)
    train_images, train_labels, val_images, val_labels = loader.prepare_dataset()
    print()
    
    # 3. åˆ›å»ºæ¨¡å‹
    print("æ­¥éª¤ 3/5: åˆ›å»ºæ¨¡å‹")
    print("-" * 80)
    model = create_model()
    model = compile_model(model)
    print_model_summary(model)
    print()
    
    # 4. è®­ç»ƒæ¨¡å‹
    print("æ­¥éª¤ 4/5: è®­ç»ƒæ¨¡å‹")
    print("-" * 80)
    callbacks = create_callbacks()
    history = train_model(
        model,
        train_data=(train_images, train_labels),
        val_data=(val_images, val_labels),
        callbacks=callbacks,
        epochs=200  # 200è½®ä¸Šé™ + 10è½®æ—©åœ
    )
    print()
    
    # 5. è¯„ä¼°æ¨¡å‹
    print("æ­¥éª¤ 5/5: è¯„ä¼°æ¨¡å‹")
    print("-" * 80)
    metrics = evaluate_model(model, val_data=(val_images, val_labels))
    print()
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    save_model(model)
    
    print("\n" + "=" * 80)
    print(" " * 30 + "è®­ç»ƒå®Œæˆ")
    print("=" * 80)
    print(f"\næœ€ç»ˆéªŒè¯é›†å®Œæ•´åŒ¹é…å‡†ç¡®ç‡: {metrics['full_match_accuracy']*100:.2f}%")
    print()
    
    return model, history, metrics


if __name__ == '__main__':
    # è®¾ç½®GPUå†…å­˜å¢é•¿
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"âœ“ æ£€æµ‹åˆ° {len(gpus)} ä¸ªGPUï¼Œå·²å¯ç”¨å†…å­˜å¢é•¿æ¨¡å¼")
        except RuntimeError as e:
            print(f"GPUè®¾ç½®é”™è¯¯: {e}")
    else:
        print("æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
    print()
    
    # è¿è¡Œè®­ç»ƒ
    main()
