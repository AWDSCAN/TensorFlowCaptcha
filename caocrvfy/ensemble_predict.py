#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é›†æˆé¢„æµ‹ - ä½¿ç”¨å¤šä¸ªcheckpointæ¨¡å‹æŠ•ç¥¨æå‡å‡†ç¡®ç‡

é€‚ç”¨åœºæ™¯ï¼šå½“å•æ¨¡å‹è¾¾åˆ°82%å·¦å³æ—¶ï¼Œä½¿ç”¨æ­¤è„šæœ¬å¯æå‡1-2%
ä½¿ç”¨æ–¹æ³•ï¼špython ensemble_predict.py
"""

import os
import numpy as np
from tensorflow import keras
from core import config
from core.data_loader import CaptchaDataLoader
from core import utils


def load_models(checkpoint_dir, checkpoint_steps):
    """
    åŠ è½½å¤šä¸ªcheckpointæ¨¡å‹
    
    å‚æ•°:
        checkpoint_dir: checkpointç›®å½•
        checkpoint_steps: æ­¥æ•°åˆ—è¡¨ï¼Œå¦‚[145000, 148000, 150000]
    
    è¿”å›:
        æ¨¡å‹åˆ—è¡¨
    """
    models = []
    
    for step in checkpoint_steps:
        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_step_{step}.keras')
        
        if not os.path.exists(checkpoint_path):
            print(f"âš ï¸  è­¦å‘Šï¼š{checkpoint_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue
        
        print(f"åŠ è½½æ¨¡å‹: checkpoint_step_{step}.keras")
        model = keras.models.load_model(checkpoint_path)
        models.append(model)
    
    print(f"\nâœ“ æˆåŠŸåŠ è½½ {len(models)} ä¸ªæ¨¡å‹")
    return models


def ensemble_predict(models, images, method='average'):
    """
    é›†æˆé¢„æµ‹ï¼šå¤šæ¨¡å‹æŠ•ç¥¨
    
    å‚æ•°:
        models: æ¨¡å‹åˆ—è¡¨
        images: è¾“å…¥å›¾åƒ
        method: 'average' - å¹³å‡æ¦‚ç‡, 'voting' - ç¡¬æŠ•ç¥¨
    
    è¿”å›:
        é›†æˆé¢„æµ‹ç»“æœ
    """
    all_predictions = []
    
    print(f"\næ‰§è¡Œé›†æˆé¢„æµ‹ï¼ˆæ–¹æ³•ï¼š{method}ï¼‰...")
    for i, model in enumerate(models):
        print(f"  æ¨¡å‹{i+1}/{len(models)} é¢„æµ‹ä¸­...")
        pred = model.predict(images, verbose=0)
        all_predictions.append(pred)
    
    # è½¬ä¸ºnumpyæ•°ç»„ï¼š(n_models, batch_size, 504)
    all_predictions = np.array(all_predictions)
    
    if method == 'average':
        # å¹³å‡æ¦‚ç‡
        ensemble_pred = np.mean(all_predictions, axis=0)
    elif method == 'voting':
        # ç¡¬æŠ•ç¥¨ï¼š>0.5ä¸º1
        binary_preds = (all_predictions > 0.5).astype(int)
        ensemble_pred = (np.sum(binary_preds, axis=0) > len(models) / 2).astype(float)
    else:
        raise ValueError(f"æœªçŸ¥æ–¹æ³•: {method}")
    
    return ensemble_pred


def evaluate_ensemble(models, val_images, val_labels, method='average'):
    """
    è¯„ä¼°é›†æˆæ¨¡å‹
    
    å‚æ•°:
        models: æ¨¡å‹åˆ—è¡¨
        val_images: éªŒè¯å›¾åƒ
        val_labels: éªŒè¯æ ‡ç­¾
        method: é›†æˆæ–¹æ³•
    
    è¿”å›:
        å‡†ç¡®ç‡
    """
    # é›†æˆé¢„æµ‹
    ensemble_pred = ensemble_predict(models, val_images, method=method)
    
    # è®¡ç®—å®Œæ•´åŒ¹é…å‡†ç¡®ç‡
    pred_texts = [utils.vector_to_text(pred) for pred in ensemble_pred]
    true_texts = [utils.vector_to_text(label) for label in val_labels]
    accuracy = utils.calculate_accuracy(true_texts, pred_texts)
    
    # æ˜¾ç¤ºå‰10ä¸ªç¤ºä¾‹
    print("\n" + "=" * 80)
    print("é›†æˆé¢„æµ‹ç¤ºä¾‹ï¼ˆå‰10ä¸ªï¼‰:")
    print("-" * 80)
    print(f"{'çœŸå®å€¼':<20}{'é¢„æµ‹å€¼':<20}{'åŒ¹é…':<10}")
    print("-" * 80)
    
    for i in range(min(10, len(true_texts))):
        match = "âœ“" if true_texts[i] == pred_texts[i] else "âœ—"
        print(f"{true_texts[i]:<20}{pred_texts[i]:<20}{match:<10}")
    
    print("=" * 80)
    
    return accuracy


def compare_methods(models, val_images, val_labels):
    """
    æ¯”è¾ƒä¸åŒé›†æˆæ–¹æ³•çš„æ•ˆæœ
    """
    print("\n" + "=" * 80)
    print("æ¯”è¾ƒä¸åŒé›†æˆæ–¹æ³•")
    print("=" * 80)
    
    methods = ['average', 'voting']
    results = {}
    
    for method in methods:
        print(f"\næµ‹è¯•æ–¹æ³•: {method}")
        accuracy = evaluate_ensemble(models, val_images, val_labels, method=method)
        results[method] = accuracy
        print(f"  å®Œæ•´åŒ¹é…å‡†ç¡®ç‡: {accuracy:.2%}")
    
    # æ‰¾å‡ºæœ€ä½³æ–¹æ³•
    best_method = max(results, key=results.get)
    print("\n" + "=" * 80)
    print(f"æœ€ä½³æ–¹æ³•: {best_method} ({results[best_method]:.2%})")
    print("=" * 80)
    
    return results


def main():
    print("=" * 80)
    print("é›†æˆé¢„æµ‹ - å¤šæ¨¡å‹æŠ•ç¥¨æå‡å‡†ç¡®ç‡")
    print("=" * 80)
    
    # 1. åŠ è½½éªŒè¯æ•°æ®
    print("\næ­¥éª¤ 1/4: åŠ è½½éªŒè¯æ•°æ®")
    print("-" * 80)
    
    loader = CaptchaDataLoader()
    loader.load_data()
    _, _, val_images, val_labels = loader.prepare_dataset()
    
    print(f"éªŒè¯é›†å¤§å°: {len(val_images)}")
    
    # 2. åŠ è½½å¤šä¸ªcheckpointæ¨¡å‹
    print("\næ­¥éª¤ 2/4: åŠ è½½checkpointæ¨¡å‹")
    print("-" * 80)
    
    # æŒ‡å®šè¦é›†æˆçš„checkpointæ­¥æ•°ï¼ˆæ ¹æ®è®­ç»ƒæ—¥å¿—é€‰æ‹©è¡¨ç°å¥½çš„ï¼‰
    checkpoint_steps = [145000, 148000, 150000, 155000, 160000]
    
    models = load_models(config.MODEL_DIR, checkpoint_steps)
    
    if len(models) < 2:
        print("\nâŒ é”™è¯¯ï¼šè‡³å°‘éœ€è¦2ä¸ªæ¨¡å‹æ‰èƒ½è¿›è¡Œé›†æˆé¢„æµ‹")
        print("   è¯·æ£€æŸ¥modelsç›®å½•ä¸‹æ˜¯å¦æœ‰è¶³å¤Ÿçš„checkpointæ–‡ä»¶")
        return
    
    # 3. è¯„ä¼°å•ä¸ªæ¨¡å‹ï¼ˆä½œä¸ºbaselineï¼‰
    print("\næ­¥éª¤ 3/4: è¯„ä¼°å•ä¸ªæ¨¡å‹ï¼ˆbaselineï¼‰")
    print("-" * 80)
    
    for i, model in enumerate(models):
        pred = model.predict(val_images, verbose=0)
        pred_texts = [utils.vector_to_text(p) for p in pred]
        true_texts = [utils.vector_to_text(label) for label in val_labels]
        acc = utils.calculate_accuracy(true_texts, pred_texts)
        print(f"  æ¨¡å‹{i+1} (step {checkpoint_steps[i]}): {acc:.2%}")
    
    # 4. é›†æˆé¢„æµ‹å¹¶æ¯”è¾ƒæ–¹æ³•
    print("\næ­¥éª¤ 4/4: é›†æˆé¢„æµ‹")
    print("-" * 80)
    
    results = compare_methods(models, val_images, val_labels)
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š é›†æˆé¢„æµ‹æ€»ç»“")
    print("=" * 80)
    print(f"ä½¿ç”¨æ¨¡å‹æ•°é‡: {len(models)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_images)}")
    print()
    
    for method, acc in results.items():
        print(f"  {method:10} : {acc:.2%}")
    
    # è®¡ç®—æå‡
    best_single = max([
        utils.calculate_accuracy(
            [utils.vector_to_text(label) for label in val_labels],
            [utils.vector_to_text(p) for p in model.predict(val_images, verbose=0)]
        )
        for model in models
    ])
    
    best_ensemble = max(results.values())
    improvement = best_ensemble - best_single
    
    print()
    print(f"æœ€ä½³å•æ¨¡å‹: {best_single:.2%}")
    print(f"æœ€ä½³é›†æˆ: {best_ensemble:.2%}")
    print(f"æå‡: {improvement:+.2%}")
    print("=" * 80)


if __name__ == '__main__':
    main()
