#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è®­ç»ƒå›è°ƒæ¨¡å—ï¼ˆå‚è€ƒcaptcha_traineræ¨¡å—åŒ–è®¾è®¡ï¼‰
åŠŸèƒ½ï¼šå®šä¹‰æ‰€æœ‰è®­ç»ƒå›è°ƒç±»ï¼Œç¡®ä¿åŠŸèƒ½å•ä¸€æ€§
"""

import os
import numpy as np
from tensorflow import keras
from . import utils


class DelayedEarlyStopping(keras.callbacks.EarlyStopping):
    """
    å»¶è¿Ÿæ—©åœå›è°ƒï¼šåœ¨æŒ‡å®šè½®æ¬¡ä¹‹å‰ä¸è§¦å‘æ—©åœ
    
    å‚è€ƒï¼šcaptcha_trainerçš„æ¨¡å—åŒ–è®¾è®¡æ€è·¯
    ç”¨é€”ï¼šå‰æœŸå……åˆ†è®­ç»ƒï¼ŒåæœŸå¯ç”¨æ—©åœç›‘æ§
    """
    def __init__(self, start_epoch=85, **kwargs):
        super().__init__(**kwargs)
        self.start_epoch = start_epoch
        self.delayed_mode = True  # æ ‡è®°æ˜¯å¦å¤„äºå»¶è¿Ÿæ¨¡å¼
    
    def on_epoch_end(self, epoch, logs=None):
        # åªåœ¨è¾¾åˆ°start_epochåæ‰è°ƒç”¨çˆ¶ç±»çš„æ—©åœé€»è¾‘
        if epoch >= self.start_epoch - 1:  # epochä»0å¼€å§‹ï¼Œç¬¬85è½®æ—¶epoch=84
            if self.delayed_mode:
                # ç¬¬ä¸€æ¬¡å¯ç”¨æ—©åœæ—¶ï¼Œæ‰“å°æç¤ºä¿¡æ¯
                print(f"\nâ° å·²è¾¾åˆ°ç¬¬{self.start_epoch}è½®ï¼Œå¯ç”¨æ—©åœç›‘æ§ï¼ˆè€å¿ƒå€¼: {self.patience}è½®ï¼‰")
                self.delayed_mode = False
            # è°ƒç”¨çˆ¶ç±»çš„æ—©åœé€»è¾‘
            super().on_epoch_end(epoch, logs)
        # å‰85è½®å®Œå…¨è·³è¿‡æ—©åœæ£€æŸ¥


class BestFullMatchCheckpoint(keras.callbacks.Callback):
    """
    ä¿å­˜æœ€ä½³å®Œæ•´åŒ¹é…å‡†ç¡®ç‡æ¨¡å‹
    
    å‚è€ƒï¼šcaptcha_trainer/validation.pyçš„å‡†ç¡®ç‡è®¡ç®—
    ç”¨é€”ï¼šè·Ÿè¸ªå¹¶ä¿å­˜å®Œæ•´éªŒè¯ç åŒ¹é…å‡†ç¡®ç‡æœ€é«˜çš„æ¨¡å‹
    """
    def __init__(self, val_data, model_dir, check_interval=5):
        """
        å‚æ•°:
            val_data: éªŒè¯æ•°æ® (X, y)
            model_dir: æ¨¡å‹ä¿å­˜ç›®å½•
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆæ¯Nè½®è®¡ç®—ä¸€æ¬¡ï¼‰
        """
        super().__init__()
        self.val_images, self.val_labels = val_data
        self.best_full_match_acc = 0
        self.model_dir = model_dir
        self.check_interval = check_interval
    
    def on_epoch_end(self, epoch, logs=None):
        # æ¯check_intervalè½®è®¡ç®—ä¸€æ¬¡å®Œæ•´åŒ¹é…å‡†ç¡®ç‡
        if (epoch + 1) % self.check_interval != 0:
            return
        
        # éšæœºé‡‡æ ·éªŒè¯æ ·æœ¬
        sample_size = min(2000, len(self.val_images))
        indices = np.random.choice(len(self.val_images), sample_size, replace=False)
        sample_images = self.val_images[indices]
        sample_labels = self.val_labels[indices]
        
        # é¢„æµ‹å¹¶è®¡ç®—å‡†ç¡®ç‡
        predictions = self.model.predict(sample_images, verbose=0)
        pred_texts = [utils.vector_to_text(pred) for pred in predictions]
        true_texts = [utils.vector_to_text(label) for label in sample_labels]
        full_match_acc = utils.calculate_accuracy(true_texts, pred_texts)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if full_match_acc > self.best_full_match_acc:
            self.best_full_match_acc = full_match_acc
            save_path = os.path.join(self.model_dir, 'best_full_match_model.keras')
            self.model.save(save_path)
            print(f"  â­ å®Œæ•´åŒ¹é…å‡†ç¡®ç‡æå‡è‡³ {full_match_acc*100:.2f}%ï¼Œæ¨¡å‹å·²ä¿å­˜ï¼")


class TrainingProgress(keras.callbacks.Callback):
    """
    è®­ç»ƒè¿›åº¦ç›‘æ§å›è°ƒ
    
    å‚è€ƒï¼šcaptcha_trainer/trains.pyçš„è®­ç»ƒæ—¥å¿—
    ç”¨é€”ï¼šæ¯è½®æ‰“å°è¯¦ç»†çš„è®­ç»ƒæŒ‡æ ‡å’Œå®Œæ•´åŒ¹é…å‡†ç¡®ç‡
    """
    def __init__(self, val_data, sample_size=1000):
        """
        å‚æ•°:
            val_data: éªŒè¯æ•°æ® (X, y)
            sample_size: é‡‡æ ·å¤§å°
        """
        super().__init__()
        self.val_images, self.val_labels = val_data
        self.sample_size = sample_size
        self.best_full_match_acc = 0
    
    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        val_loss = logs.get('val_loss', 0)
        val_binary_acc = logs.get('val_binary_accuracy', 0)
        
        # è·å–å½“å‰å­¦ä¹ ç‡ï¼ˆå…¼å®¹ä¸åŒKerasç‰ˆæœ¬ï¼‰
        try:
            current_lr = float(self.model.optimizer.learning_rate.numpy())
        except:
            try:
                import tensorflow.keras.backend as K
                current_lr = float(K.get_value(self.model.optimizer.lr))
            except:
                current_lr = 0.001  # é»˜è®¤å€¼
        
        # è®¡ç®—å®Œæ•´åŒ¹é…å‡†ç¡®ç‡ï¼ˆé‡‡æ ·åŠ å¿«é€Ÿåº¦ï¼‰
        sample_size = min(self.sample_size, len(self.val_images))
        indices = np.random.choice(len(self.val_images), sample_size, replace=False)
        sample_images = self.val_images[indices]
        sample_labels = self.val_labels[indices]
        
        predictions = self.model.predict(sample_images, verbose=0)
        pred_texts = [utils.vector_to_text(pred) for pred in predictions]
        true_texts = [utils.vector_to_text(label) for label in sample_labels]
        full_match_acc = utils.calculate_accuracy(true_texts, pred_texts)
        
        # æ‰“å°è®­ç»ƒè¿›åº¦
        print(f"\n[Epoch {epoch+1}] è®­ç»ƒæŸå¤±: {logs.get('loss', 0):.4f} | "
              f"éªŒè¯æŸå¤±: {val_loss:.4f} | "
              f"äºŒè¿›åˆ¶å‡†ç¡®ç‡: {val_binary_acc:.4f} | "
              f"å®Œæ•´åŒ¹é…: {full_match_acc*100:.2f}% | "
              f"å­¦ä¹ ç‡: {current_lr:.6f}")
        
        # è·Ÿè¸ªæœ€ä½³å®Œæ•´åŒ¹é…å‡†ç¡®ç‡
        if full_match_acc > self.best_full_match_acc:
            self.best_full_match_acc = full_match_acc
            print(f"    â¬† å®Œæ•´åŒ¹é…å‡†ç¡®ç‡æå‡ï¼å½“å‰: {full_match_acc*100:.2f}% "
                  f"(å†å²æœ€ä½³: {self.best_full_match_acc*100:.2f}%)")


class StepBasedCallbacks(keras.callbacks.Callback):
    """
    Step-basedè®­ç»ƒç­–ç•¥ï¼ˆå‚è€ƒcaptcha_trainer/trains.pyï¼‰
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - æ¯save_stepæ­¥ä¿å­˜checkpoint
    - æ¯validation_stepsæ­¥éªŒè¯
    - å¤šæ¡ä»¶ç»ˆæ­¢ï¼šaccuracy AND loss AND steps
    - è‡ªåŠ¨æ¸…ç†æ—§checkpointï¼Œåªä¿ç•™æœ€è¿‘Nä¸ª
    
    å‚è€ƒï¼šcaptcha_trainer/trains.pyçš„achieve_condé€»è¾‘
    """
    def __init__(self, val_data, model_dir, save_step=100, validation_steps=500,
                 end_acc=0.95, end_loss=0.01, max_steps=50000, max_checkpoints=5):
        """
        å‚æ•°:
            val_data: éªŒè¯æ•°æ® (X, y)
            model_dir: æ¨¡å‹ä¿å­˜ç›®å½•
            save_step: ä¿å­˜é—´éš”ï¼ˆæ­¥ï¼‰
            validation_steps: éªŒè¯é—´éš”ï¼ˆæ­¥ï¼‰
            end_acc: ç›®æ ‡å‡†ç¡®ç‡
            end_loss: ç›®æ ‡æŸå¤±
            max_steps: æœ€å¤§æ­¥æ•°
            max_checkpoints: æœ€å¤šä¿ç•™çš„checkpointæ•°é‡ï¼ˆé»˜è®¤5ä¸ªï¼‰
        """
        super().__init__()
        self.val_images, self.val_labels = val_data
        self.model_dir = model_dir
        self.save_step = save_step
        self.validation_steps = validation_steps
        self.end_acc = end_acc
        self.end_loss = end_loss
        self.max_steps = max_steps
        self.max_checkpoints = max_checkpoints
        self.current_step = 0
        self.best_val_acc = 0
        self.best_val_loss = float('inf')
        self.checkpoint_files = []  # è®°å½•å·²ä¿å­˜çš„checkpointæ–‡ä»¶
    
    def on_batch_end(self, batch, logs=None):
        """æ¯ä¸ªbatchç»“æŸæ—¶è°ƒç”¨"""
        self.current_step += 1
        logs = logs or {}
        
        # æ¯save_stepæ­¥ä¿å­˜checkpoint
        if self.current_step % self.save_step == 0:
            checkpoint_path = os.path.join(self.model_dir, f'checkpoint_step_{self.current_step}.keras')
            self.model.save(checkpoint_path)
            print(f"\n  ğŸ’¾ Step {self.current_step}: ä¿å­˜checkpoint (loss={logs.get('loss', 0):.4f})")
            
            # è®°å½•checkpointæ–‡ä»¶
            self.checkpoint_files.append(checkpoint_path)
            
            # æ¸…ç†æ—§checkpointï¼Œåªä¿ç•™æœ€è¿‘çš„Nä¸ª
            if len(self.checkpoint_files) > self.max_checkpoints:
                old_checkpoint = self.checkpoint_files.pop(0)
                try:
                    if os.path.exists(old_checkpoint):
                        os.remove(old_checkpoint)
                        print(f"  ğŸ—‘ï¸  åˆ é™¤æ—§checkpoint: {os.path.basename(old_checkpoint)}")
                except Exception as e:
                    print(f"  âš ï¸  åˆ é™¤checkpointå¤±è´¥: {e}")
        
        # æ¯validation_stepsæ­¥éªŒè¯
        if self.current_step % self.validation_steps == 0:
            self._validate_and_check_termination()
    
    def _validate_and_check_termination(self):
        """
        æ‰§è¡ŒéªŒè¯å¹¶æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
        å‚è€ƒï¼šcaptcha_trainer/trains.pyçš„éªŒè¯ç­–ç•¥
        """
        # é‡‡æ ·1000ä¸ªéªŒè¯æ ·æœ¬
        sample_size = min(1000, len(self.val_images))
        indices = np.random.choice(len(self.val_images), sample_size, replace=False)
        sample_images = self.val_images[indices]
        sample_labels = self.val_labels[indices]
        
        # è®¡ç®—éªŒè¯æŸå¤±å’Œå‡†ç¡®ç‡
        val_results = self.model.evaluate(sample_images, sample_labels, verbose=0)
        val_loss = val_results[0]
        val_binary_acc = val_results[1]
        
        # è®¡ç®—å®Œæ•´åŒ¹é…å‡†ç¡®ç‡
        predictions = self.model.predict(sample_images, verbose=0)
        pred_texts = [utils.vector_to_text(pred) for pred in predictions]
        true_texts = [utils.vector_to_text(label) for label in sample_labels]
        full_match_acc = utils.calculate_accuracy(true_texts, pred_texts)
        
        # è·å–å½“å‰å­¦ä¹ ç‡
        current_lr = self._get_current_lr()
        
        # æ‰“å°éªŒè¯ç»“æœ
        print(f"\n  ğŸ“Š Step {self.current_step} éªŒè¯ç»“æœ:")
        print(f"      éªŒè¯æŸå¤±: {val_loss:.4f} | äºŒè¿›åˆ¶å‡†ç¡®ç‡: {val_binary_acc:.4f}")
        print(f"      å®Œæ•´åŒ¹é…: {full_match_acc*100:.2f}% | å­¦ä¹ ç‡: {current_lr:.6f}")
        
        # æ›´æ–°æœ€ä½³æŒ‡æ ‡
        if full_match_acc > self.best_val_acc:
            self.best_val_acc = full_match_acc
            print(f"      â¬† æœ€ä½³å®Œæ•´åŒ¹é…å‡†ç¡®ç‡: {self.best_val_acc*100:.2f}%")
        if val_loss < self.best_val_loss:
            self.best_val_loss = val_loss
            print(f"      â¬‡ æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.4f}")
        
        # å¤šæ¡ä»¶ç»ˆæ­¢æ£€æŸ¥ï¼ˆå‚è€ƒtrains.pyçš„achieve_condï¼‰
        if self._should_terminate(full_match_acc, val_loss):
            self._print_termination_info(full_match_acc, val_loss)
            self.model.stop_training = True
    
    def _get_current_lr(self):
        """è·å–å½“å‰å­¦ä¹ ç‡"""
        try:
            return float(self.model.optimizer.learning_rate(self.current_step))
        except:
            try:
                return float(self.model.optimizer.learning_rate.numpy())
            except:
                return 0.001
    
    def _should_terminate(self, full_match_acc, val_loss):
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»ˆæ­¢è®­ç»ƒ
        å‚è€ƒï¼šcaptcha_trainer/trains.pyçš„achieve_cond
        """
        achieve_accuracy = full_match_acc >= self.end_acc
        achieve_loss = val_loss <= self.end_loss
        achieve_steps = self.current_step >= 10000  # è‡³å°‘è®­ç»ƒ10000æ­¥
        over_max_steps = self.current_step > self.max_steps
        
        return (achieve_accuracy and achieve_loss and achieve_steps) or over_max_steps
    
    def _print_termination_info(self, full_match_acc, val_loss):
        """æ‰“å°ç»ˆæ­¢ä¿¡æ¯"""
        achieve_accuracy = full_match_acc >= self.end_acc
        achieve_loss = val_loss <= self.end_loss
        achieve_steps = self.current_step >= 10000
        over_max_steps = self.current_step > self.max_steps
        
        print(f"\n  ğŸ¯ æ»¡è¶³ç»ˆæ­¢æ¡ä»¶:")
        print(f"      å‡†ç¡®ç‡è¾¾æ ‡: {achieve_accuracy} (>={self.end_acc:.2%})")
        print(f"      æŸå¤±è¾¾æ ‡: {achieve_loss} (<={self.end_loss:.4f})")
        print(f"      æ­¥æ•°è¾¾æ ‡: {achieve_steps} (>={10000})")
        print(f"      æˆ–è¶…è¿‡æœ€å¤§æ­¥æ•°: {over_max_steps} (>{self.max_steps})")
        print(f"\n  âœ… æå‰ç»ˆæ­¢è®­ç»ƒï¼")


def create_callbacks(model_dir, log_dir, val_data, 
                     use_step_based=True, use_early_stopping=False,
                     checkpoint_save_step=500, validation_steps=500,
                     max_checkpoints_keep=5, end_acc=0.85, max_steps=150000):
    """
    åˆ›å»ºè®­ç»ƒå›è°ƒå‡½æ•°ï¼ˆæ¨¡å—åŒ–è®¾è®¡ï¼‰
    
    å‚è€ƒï¼šcaptcha_trainerçš„æ¨¡å—åŒ–å›è°ƒè®¾è®¡
    åŠŸèƒ½ï¼šæ ¹æ®é…ç½®ç»„è£…æ‰€éœ€çš„å›è°ƒ
    
    å‚æ•°:
        model_dir: æ¨¡å‹ä¿å­˜ç›®å½•
        log_dir: æ—¥å¿—ä¿å­˜ç›®å½•
        val_data: éªŒè¯æ•°æ® (X, y)
        use_step_based: æ˜¯å¦ä½¿ç”¨step-basedç­–ç•¥
        use_early_stopping: æ˜¯å¦ä½¿ç”¨æ—©åœï¼ˆä¸å»ºè®®ä¸step-basedåŒæ—¶ä½¿ç”¨ï¼‰
        checkpoint_save_step: checkpointä¿å­˜é—´éš”ï¼ˆæ­¥ï¼‰- é»˜è®¤500æ­¥ï¼ˆé¿å…ç£ç›˜å æ»¡ï¼‰
        validation_steps: éªŒè¯é—´éš”ï¼ˆæ­¥ï¼‰- é»˜è®¤500æ­¥
        max_checkpoints_keep: æœ€å¤šä¿ç•™çš„checkpointæ•°é‡ï¼ˆé»˜è®¤5ä¸ªï¼‰
        end_acc: ç›®æ ‡å‡†ç¡®ç‡ï¼ˆé»˜è®¤0.85å³85%ï¼‰
        max_steps: æœ€å¤§è®­ç»ƒæ­¥æ•°ï¼ˆé»˜è®¤150000ï¼‰
    
    è¿”å›:
        å›è°ƒå‡½æ•°åˆ—è¡¨
    """
    import time
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(model_dir, exist_ok=True)
    os.makedirs(log_dir, exist_ok=True)
    
    callbacks = []
    
    # 1. æ¨¡å‹æ£€æŸ¥ç‚¹ï¼šä¿å­˜æœ€ä¼˜æ¨¡å‹
    checkpoint_path = os.path.join(model_dir, 'best_model.keras')
    checkpoint = keras.callbacks.ModelCheckpoint(
        filepath=checkpoint_path,
        monitor='val_loss',
        mode='min',
        save_best_only=True,
        save_weights_only=False,
        verbose=1
    )
    callbacks.append(checkpoint)
    
    # 2. TensorBoardï¼šå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
    tensorboard_log_dir = os.path.join(log_dir, f'run_{time.strftime("%Y%m%d_%H%M%S")}')
    tensorboard = keras.callbacks.TensorBoard(
        log_dir=tensorboard_log_dir,
        histogram_freq=1,
        write_graph=True,
        write_images=False
    )
    callbacks.append(tensorboard)
    
    # 3. Step-basedç­–ç•¥ï¼ˆå‚è€ƒcaptcha_trainer/trains.pyï¼‰
    if use_step_based:
        step_based = StepBasedCallbacks(
            val_data=val_data,
            model_dir=model_dir,
            save_step=checkpoint_save_step,  # ä½¿ç”¨é…ç½®çš„ä¿å­˜é—´éš”
            validation_steps=validation_steps,
            end_acc=end_acc,  # ä½¿ç”¨ä¼ å…¥çš„ç›®æ ‡å‡†ç¡®ç‡
            end_loss=0.05,
            max_steps=max_steps,  # ä½¿ç”¨ä¼ å…¥çš„æœ€å¤§æ­¥æ•°
            max_checkpoints=max_checkpoints_keep  # åªä¿ç•™Nä¸ªcheckpoint
        )
        callbacks.append(step_based)
        print(f"âœ“ å¯ç”¨Step-basedè®­ç»ƒç­–ç•¥ï¼ˆæ¯{validation_steps}æ­¥éªŒè¯ï¼Œæ¯{checkpoint_save_step}æ­¥ä¿å­˜ï¼Œä¿ç•™{max_checkpoints_keep}ä¸ªcheckpointï¼‰")
        print(f"  ç›®æ ‡å‡†ç¡®ç‡: {end_acc:.1%} | æœ€å¤§æ­¥æ•°: {max_steps}")
    
    # 4. æ—©åœï¼ˆå¯é€‰ï¼Œä¸å»ºè®®ä¸step-basedåŒæ—¶ä½¿ç”¨ï¼‰
    if use_early_stopping and not use_step_based:
        early_stop = DelayedEarlyStopping(
            start_epoch=50,
            monitor='val_loss',
            mode='min',
            patience=35,
            verbose=1,
            restore_best_weights=True,
            min_delta=0.00005
        )
        callbacks.append(early_stop)
        print("âœ“ å¯ç”¨å»¶è¿Ÿæ—©åœç­–ç•¥ï¼ˆç¬¬50è½®åç›‘æ§ï¼‰")
    
    # 5. æœ€ä½³å®Œæ•´åŒ¹é…æ¨¡å‹ä¿å­˜
    if val_data is not None:
        best_match = BestFullMatchCheckpoint(
            val_data=val_data, 
            model_dir=model_dir,
            check_interval=5
        )
        callbacks.append(best_match)
    
    # 6. è®­ç»ƒè¿›åº¦ç›‘æ§
    if val_data is not None:
        progress = TrainingProgress(val_data=val_data, sample_size=1000)
        callbacks.append(progress)
    
    return callbacks
